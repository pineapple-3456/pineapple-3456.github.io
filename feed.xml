<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://pinapple-3456.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://pinapple-3456.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-12-14T15:04:42+00:00</updated><id>https://pinapple-3456.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">消耗战的演化均衡策略</title><link href="https://pinapple-3456.github.io/blog/2025/%E6%B6%88%E8%80%97%E6%88%98/" rel="alternate" type="text/html" title="消耗战的演化均衡策略"/><published>2025-12-14T00:00:00+00:00</published><updated>2025-12-14T00:00:00+00:00</updated><id>https://pinapple-3456.github.io/blog/2025/%E6%B6%88%E8%80%97%E6%88%98</id><content type="html" xml:base="https://pinapple-3456.github.io/blog/2025/%E6%B6%88%E8%80%97%E6%88%98/"><![CDATA[<p>假设无限大的种群，个体随机配对为一块地盘而展开竞争，胜者能够获得这个地盘的全部资源 \(V\) ，败者得不到任何收益。输赢取决于谁付出成本更多，付出更多成本的个体会赢得竞争。如果双方打算付出的成本一致，则收益是随机的（几乎不会发生）。对于打算付出成本为 \(m\) 的个体，如果对方打算付出更多成本，即 \(m + \delta\) ，则对方获得胜利。然而，一次竞争的成本是由败者付出的成本决定的，因为当一方失败时，竞争就会结束。所以即使是胜者，实际上也只需要付出 \(m\) 的成本。于是就有如下的支付矩阵：</p> \[\begin{array}{c|cc} &amp; m &amp; m + \delta \\ \hline m &amp; (V/2) - m &amp; -m \\ m + \delta &amp; V - m &amp; (V/2) - m - \delta \end{array}\] <p>没有纯策略ESS。可以假设有一个纯策略，所有个体都付出某个成本 \(m\) ，那所有个体回报均为 \((V/2) - m\) ，此时付出更多成本 \(m + \delta\) 的策略就能获得更多收益，因此成本 \(m\) 的纯策略就不可能维持。另外，如果 \((V/2) - m &lt; 0\) ，不付出任何成本也会减少损失，从而获得优势，使纯策略 \(m\) 无法维持。因此，如果有ESS，一定是混合策略。</p> <p>当前的消耗战模型中，假设所有个体采取混合策略 \(I\) ，分布是 \(p(x)\) 。根据Bishop-Cannings定理，如果混合策略是ESS，那么构成混合策略的每一种纯策略必须具有相同的收益。因为如果其中任何一个纯策略具有更高的收益，个体就会全部采用高收益策略，从而使混合策略变为纯策略。因此，如果一个混合策略 \(I\) 是由离散的纯策略 \((m_1, m_2, m_3, ... , m_i)\) 构成的，那么必须满足 \(E(m_1, I) = E(m_2,I) = E(m_3, I) = ... = E(m_i, I)\) 。如果构成 \(I\) 的纯策略是 \(m\) 连续的，那么无论 \(m\) 取何值， \(E(m, I)\) 都应该是相等的，也就是 \(\frac{\partial E(m, I)}{\partial m} = 0\) 。因此，寻找混合策略的分布，首先需要找到使 \(\frac{\partial E(m, I)}{\partial m} = 0\) 的 \(p(x)\) 。</p> <p>当 \(x &lt; m\) 时，采取 \(m\) 策略会获胜，并付出成本 \(x\) (付出的成本取决于失败者)，收益为 \((V-x)\) 。当 \(x &gt; m\) 时，采取 \(m\) 策略会失败，收益为 \(-m\) 。将成功和失败的收益根据概率进行加权得到 \(E(m, I)\) ：</p> \[E(m, I) = \int_0^m (V-x) \, p(x) dx - \int_m^\infty m \, p(x)dx\] <p>对于左半部分 :</p> \[\frac{d}{dm} \int_0^m (V-x) \, p(x) dx = (V-m)p(m) = V\, p(m) - m \, p(m)\] <p>对于右半部分，根据乘积法则可以得到:</p> \[\frac{d}{dm}[ m \int_m^\infty p(x)dx ]= \int_m^\infty p(x)dx + m · [-p(m)] = \int_m^\infty p(x)dx - m \, p(m)\] <p>所以 \(\frac{d}{dm} E(m,I) = 0\) 实际上就是:</p> \[V\, p(m) = \int_m^\infty p(x)dx\] <p>两边同时求导：</p> \[V · \frac{dp(m)}{dm} = -p(m)\] \[\frac{1}{p(m)}\frac{dp(m)}{dm} = -\frac{1}{V}\] <p>两边同时积分：</p> \[\int \frac{1}{p(m)}dp(m) = -\int \frac{1}{V}dm + C\] \[ln[p(m)]=-\frac{m}{V}+C\] \[p(m) = e^{-m/V}·e^C\] <p>令常数 \(K = e^C\) ：</p> \[p(m) = Ke^{-m/V}\] <p>将 \(p(m)\) 带入到 \(\int_0^\infty p(x)dx = 1\) 中：</p> \[\int_0^\infty Ke^{-x/V}dx = 1\] <p>求原函数：</p> \[K \left[ -V e^{-x/V}\right]_0^\infty = 1\] \[K = \frac{1}{V}\] <p>所以：</p> \[p(x) = \frac{1}{V} e^{-x/V}\] <p>这样就得到了混合策略 \(I\) 应该具有的形态，但是混合策略要成为ESS，还应该满足 \(E(I, m) &gt; E(m, m)\) 。也就是说，混合策略不但存在，而且应该比任何一种纯策略都更具适应性。类似于前面 \(E(m, I)\) 的形式，可以得到：</p> \[E(I, m) = \int_0^m -x p(x) dx +\int_m^\infty (V-m) p(x) dx\] <p>对于左半部分，带入前面求得的 \(p(x)\) ：</p> \[\int_0^m -x p(x) dx = \int_0^m -\frac{x}{V} e^{-x/V} dx = \left[ (x+V)e^{-x/V} \right]_0^m = (m+V) e^{-m/V} -V\] <p>对于右半部分，同样：</p> \[\int_m^\infty (V-m) p(x) dx = \int_m^\infty (V-m) \frac{1}{V} e^{-x/V} dx = \left[ (V-m)·\frac{1}{V}·(-Ve^{x/V})\right]_m^\infty = (V-m) e^{-m/V}\] <p>因此：</p> \[E(I,m) = 2Ve^{-m/V}-V\] <p>而 \(E(m,m)\) 是平局，双方受益均为 \(\frac{V}{2} - m\) ，因此 \(E(I, m) &gt; E(m, m)\) 实际上就是：</p> \[2Ve^{-m/V} - \frac{3V}{2} + m &gt; 0\] <p>令左边为 \(f(m)\) ，对 \(f(m)\) 求导：</p> \[f'(m) = 2e^{-m/V}+1\] <p>令 \(f'(m) = 0\) ，得到 \(m = V\text{ln}2\) ，带回到 \(f(m)\) ，得到最小值为 \((\text{ln}2-0.5)V\) ，因为 \(\text{ln}2-0.5\) 和 \(V\) 都大于0，所以 \(f(m)\) 最小值大于0。所以 \(E(I, m) &gt; E(m, m)\) 得证。</p> <p>因此，混合策略 \(I\) 是ESS，分布为 \(\frac{1}{V} e^{-x/V}\) 。</p>]]></content><author><name></name></author><category term="演化博弈"/><category term="其它"/><summary type="html"><![CDATA[《演化与博弈论》消耗战章节公式3.1和3.2的推导]]></summary></entry><entry><title type="html">教育测量中的项目反应理论与合理值</title><link href="https://pinapple-3456.github.io/blog/2025/%E6%95%99%E8%82%B2%E6%B5%8B%E9%87%8F%E4%B8%AD%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%8F%8D%E5%BA%94%E7%90%86%E8%AE%BA%E4%B8%8E%E5%90%88%E7%90%86%E5%80%BC/" rel="alternate" type="text/html" title="教育测量中的项目反应理论与合理值"/><published>2025-02-07T00:00:00+00:00</published><updated>2025-02-07T00:00:00+00:00</updated><id>https://pinapple-3456.github.io/blog/2025/%E6%95%99%E8%82%B2%E6%B5%8B%E9%87%8F%E4%B8%AD%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%8F%8D%E5%BA%94%E7%90%86%E8%AE%BA%E4%B8%8E%E5%90%88%E7%90%86%E5%80%BC</id><content type="html" xml:base="https://pinapple-3456.github.io/blog/2025/%E6%95%99%E8%82%B2%E6%B5%8B%E9%87%8F%E4%B8%AD%E7%9A%84%E9%A1%B9%E7%9B%AE%E5%8F%8D%E5%BA%94%E7%90%86%E8%AE%BA%E4%B8%8E%E5%90%88%E7%90%86%E5%80%BC/"><![CDATA[<p>在国际大型教育调查 (Large-Scale Assessment, LSA) 中，通常需要评估学生的认知能力。不同于一般的考试，LSA中的认知能力测验一般是作为整个调查的一部分来进行，时间有限，学生只能从题库中抽取少量问题来回答。因此，每个学生实际上进行了不同的子测验。每个子测验难度可能是不同的，这就导致来自不同子测验的分数无法直接比较。假如某一个学生抽到了难度为2的题目，正确概率为0.40，而另一个学生抽到了难度为1的题目，正确概率为0.65。因为测验难度不同，直接根据正确概率认定后者能力高于前者是不合适的，此时不同学生的分数不能相互比较。然而，在后期进行数据分析时，我们希望每个学生的测验分数处在同一个可比较的系统上。</p> <p>项目反应理论 (Item Response Theory, IRT) 有助于解决这一问题。IRT的基本思想是，测验项目的正确作答概率是学生潜在能力的函数，因此可以通过测验项目的正确作答概率来计算潜在能力。对于每个测验项目，都建立了正确概率与能力的唯一确定关系，这样就把不同的测验项目都纳入到同一个系统当中，进而可以进行比较。例如，对于难度为2的测验项目，可以估计正确概率为0.40所代表的能力值，同样对于难度为1的测验项目也可以估计正确概率为0.65所代表的能力值，进而可以直接比较不同学生的能力。</p> <h1 id="rasch模型">Rasch模型</h1> <p>最简单的IRT模型是 Rasch 模型，也叫做单参数模型 (1PLM)，因为只有一个参数 (难度b)。适合于迫选题目，这类题目的作答只有正确和错误两种可能。对于第 \(i\) 个测验项目，项目特征函数 (Item Characteristic Function, ICF) 是一个Logit函数：</p> \[\begin{align} P(x_i=1) = \frac{exp(\theta-b_i)}{1+exp(\theta-b_i)} \end{align}\] <p>这里 \(P(x_i=1)\) 表示正确作答的概率， \(\theta\) 表示学生的能力， \(b_i\) 表示项目的难度参数。同时也有错误作答的概率 \(P(x_i=0) = 1-P(x_i=1)=1/[1+exp(\theta-b_i)]\) 。因此：</p> \[\begin{align} \frac{P(x_i=1)}{P(x_i=0)} = \exp(\theta-b_i)\\ \ln \left ( \frac{P(x_i=1)}{P(x_i=0)}\right ) = \theta-b_i \\ \end{align}\] <p>表明正确和错误的几率比 (odds) 随着能力提升而提升。但只有能力和项目难度相当时，几率比和能力才等比变化。当能力远高于项目难度时，几率比的变化逐渐减缓，即天花板效应，同理也有地板效应，因此对几率比取对数。可以绘制项目特征曲线 (Item Characteristic Curve, ICC)：</p> <pre><code class="language-{r}">b &lt;- 0  #难度为0

rasch_curve &lt;- curve(exp(theta-b)/(1+exp(theta-b)), type = "l",  #绘制曲线
                     xname = 'theta', xlim = c(-3, 3), 
                     xlab = 'theta', ylab = 'prob(x=1)')

segments(x0 = 1, y0 = 0, 
         x1 = 1, y1 = exp(1-b)/(1+exp(1-b)), lty = 2)  #标记能力为1时的正确作答概率

segments(x0 = -4, y0 = exp(1-b)/(1+exp(1-b)), 
         x1 = 1, y1 = exp(1-b)/(1+exp(1-b)), lty = 2)
</code></pre> <p><img src="/assets/img/教育测量中的合理值figure1.png" alt="figure1" height="70%" width="70%"/></p> <p>图1是难度为0时的ICC。正确作答概率取决于能力与项目难度的相对位置。假设一个测验项目难度为0，有一个学生能力等于1，那他正确作答概率就在0.73左右。注意难度和学生的能力在同一尺度上，可以相互比较。ICC的特点是：能力与难度0接近时，正确概率与能力几乎等比变化，而能力与与难度相差较远时，正确概率的变化幅度逐渐减缓，呈现出S型。除了Rasch模型，其他IRT模型的ICF也都具有这个特点，因为它们都是Logit或Probit函数的变体 (正态分布和逻辑分布的累积函数)。</p> <p>实际上，IRT最初的模型是基于Probit函数建立的。设想一个测验项目的难度是正态分布的，学生正确作答的概率应该是难度分布中低于其能力的部分的累积，因此是正态分布的累积函数。使用Logit函数作为ICF的一般形式是因为逻辑分布的累积函数有解析表达式，而正态分布没有，因此Logit的计算更方便。逻辑分布更接近于自由度为7的t分布，在后面会看到，使用双参数模型时，ICF通常会被矫正为更接近Probit函数的形式。</p> <p>Rasch是最简单的IRT模型，LSA中使用的模型一般要更复杂一些。例如 PISA 2018 使用了双参数Logit模型 (2PLM)，它是Rasch模型的推广：</p> \[\begin{align} P(x_i=1) = \frac{exp(Da_i(\theta-b_i))}{1+exp(Da_i(\theta-b_i))} \end{align}\] <p>和Rasch模型相比，加入了区分度参数 \(a_i\) 和比例因子 \(D\) 。区分度参数在 ICC 曲线中体现为曲线的陡峭程度，当曲线更陡峭时，相同的能力差异对应的正确率差异更大，对比区分度为1(蓝色) 和2(红色) 的ICC曲线：</p> <pre><code class="language-{r}">d &lt;- 1.7  #比例因子

plotCurve &lt;- function(a, b, col){
  curve(exp(d*a*(theta-b))/(1+exp(d*a*(theta-b))), type = "l", col = col,  #绘制曲线
        xname = 'theta', xlim = c(-3, 3), ylim = c(0, 1),
        xlab = 'theta', ylab = 'prob(x=1)')
}

plotCurve(a = 1, b = 0, col = 'blue');par(new=TRUE)  #区分度为1（蓝色）
plotCurve(a = 2, b = 0, col = 'red')  #区分度为2（红色）
</code></pre> <p><img src="/assets/img/教育测量中的合理值figure2.png" alt="figure2" height="70%" width="70%"/></p> <p>比例因子D是为了使ICC曲线更接近Probit曲线，正如上文提到的。D 通常是常数1.7。可以对比Probit曲线 (蓝色)、使用D = 1.7调整的Logit曲线 (红色) 和没有调整的Logit曲线 (绿色)，会发现经过D调整后的Logit曲线与Probit更接近：</p> <pre><code class="language-{r}">curve(pnorm(theta), type = "l", col = 'blue', #Probit曲线（蓝色）
      xname = 'theta', xlim = c(-3, 3), ylim = c(0, 1),
      xlab = 'theta', ylab = 'prob(x=1)')
par(new=TRUE)

curve(plogis(1.7*theta), type = "l",  col = 'red',  #经过D调整的Logit曲线（红色）
      xname = 'theta', xlim = c(-3, 3), ylim = c(0, 1),
      xlab = 'theta', ylab = 'prob(x=1)')
par(new=TRUE)

curve(plogis(theta), type = "l", col = 'green',  #未调整的Logit曲线（绿色）
      xname = 'theta', xlim = c(-3, 3), ylim = c(0, 1),
      xlab = 'theta', ylab = 'prob(x=1)')
</code></pre> <p><img src="/assets/img/教育测量中的合理值figure3.png" alt="figure3" height="70%" width="70%"/></p> <h1 id="合理值">合理值</h1> <p>对一个群体进行施测后，可以通过加权极大似然估计 (Weighted Maximum Likelihood) 得到每个学生的能力估计，这种估计量被称为WLE估计量 (Weighted Likelihood Estimate)。WLE估计在估计个别学生能力时是合理的，但是在LSA中，除了个别学生的能力，我们还想要得到每个地区的能力分布。这时使用WLE估计是不合理的。WLE估计存在误差，因此一组学生WLE分数的方差一定高于实际能力的方差，这就使得同一地区所有学生WLE分数的方差是地区方差的高估。我们知道在经典测验理论中，真分数的方差等于观测分数的方差乘以信度，而信度总是小于1，因此观测分数方差总是高于真分数方差。类似地，在项目反应理论中，人群能力的方差等于WLE分数的方差乘以信度，因此WLE分数的方差高估了实际能力的方差。</p> <p>模拟一组测验数据：</p> <pre><code class="language-{r}">generateRasch &lt;- function(N, I) {
  theta &lt;- rnorm(N) #随机生成N个学生的能力theta，均值为0，方差为1
  b &lt;- seq(-2, 2, len = I)  #生成I个项目的难度，最低-2，最高2
  p &lt;- plogis(outer(theta, b, "-"))  #计算各theta和b下的正确作答概率
  resp &lt;- 1 * (p &gt; matrix(runif(N * I) , nrow = N , ncol = I))  #根据正确概率生成反应数据
  colnames(resp) &lt;- paste("I", 1:I, sep = "")
  return(list(resp = resp, theta = theta, b = b))
}

# 生成10000个学生在30个项目上的Rasch数据
generateData &lt;- generateRasch(10000, 30)
resp &lt;- generateData$resp
theta &lt;- generateData$theta
b &lt;- generateData$db
</code></pre> <p>计算所有学生的WLE分数，对比WLE分数方差和实际能力方差：</p> <pre><code class="language-{r}">library(TAM)
jml_model &lt;- tam.jml(resp)
wle &lt;- jml_model$WLE
var(wle)
## [1] 1.253939
var(theta)
## [1] 1.019041
</code></pre> <p>可以看到，在模拟的数据中，实际能力的方差为1.02，但WLE分数的方差为1.25。</p> <p>为了得到方差的无偏估计，LSA的认知测验一般使用边缘极大似然法 (Marginal Maximum Likelihood, MML) 来估计学生的能力分布。MML直接估计群体的能力分布，而不是先估计个体能力再进行汇总，可以直接得到总体方差的无偏估计。MML可以看做一种贝叶斯估计，群体的能力分布即是先验分布，可以通过群体的能力分布进一步来估计个别学生的能力分布，即后验分布。根据贝叶斯定理，第 \(j\) 个学生能力的后验分布为：</p> \[\begin{align} h(\theta|x) = \frac{f(x|\theta)g(\theta)}{f(x)} \end{align}\] <p>其中 \(f(x\vert\theta)\) 是学生能力为 \(\theta\) 时做出反应序列 \(x\) 的概率。 \(g(\theta)\) 是能力的先验分布，在LSA中一般是一个国家或地区的学生能力分布。 \(f(x)\) 是不考虑能力的反应序列分布。</p> <p>通过学生能力的后验分布，也可以计算各国家或地区的学生能力分布：</p> \[\begin{align} g(\theta)=\int h(\theta|x) f(x) d x \end{align}\] <p>仍然使用上面生成的数据，通过MML估计来计算学生能力方差：</p> <pre><code class="language-{r}">model_mml &lt;- tam.mml(resp)  
model_mml$variance 
</code></pre> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>         [,1]
[1,] 1.015029
</code></pre></div></div> <p>可以看到，估计的方差为1.02，与实际能力方差非常接近。</p> <p>注意MML并不给出学生能力的点估计，而是对每个学生给出一个能力的分布。因此LSA中认知测验数据并不像问卷数据一样直接给出一个分数，而是对每个学生给出其能力后验分布的抽样。例如PISA一般会对每个学生给出10个抽样，这些抽样相当于每个学生能力的经验分布。抽样的值被称为合理值 (Plausible Value, PV)。</p> <p>注意在使用PV的过程中，不可以将学生的多个PV的均值作为学生能力的点估计，因为这样会低估群体的方差：</p> <pre><code class="language-{r}">pv &lt;- tam.pv(model_mml)  #对每个学生计算10个PV
pv_10 &lt;- pv$pv[, -1]
var(apply(pv_10, 1, mean))  #将每个学生计算pv均值再计算方差
## [1] 0.8640724
</code></pre> <p>正确的做法是只使用一个PV。一个PV仍然能够得到方差的无偏估计：</p> <pre><code class="language-{r}">var(pv_10[,1])
## [1] 1.031991
</code></pre> <p>但最好利用全部的数据，对于数据中给出的10个PV，可以对每个pv分别计算方差，然后再取10个方差的均值：</p> <pre><code class="language-{r}">mean(apply(pv_10, 2, var)) 
## [1] 1.014203
</code></pre> <h2 id="参考资料">参考资料：</h2> <ul> <li> <p>Margaret Wu, Hak Ping Tam, Tsung-Hau Jen. Educational Measurement for Applied Researchers: Theory into Practice.</p> </li> <li> <p><a href="https://edmeasurementsurveys.com/index.html">A Course on Test and Item Analyses</a></p> </li> <li> <p>OECD. PISA 2018 Techincal report. Chapter 9 Scaling PISA data.</p> </li> </ul>]]></content><author><name></name></author><category term="毕业论文"/><category term="心理学"/><summary type="html"><![CDATA[Rasch模型和PV的含义]]></summary></entry><entry><title type="html">使用lme4建立线性混合模型</title><link href="https://pinapple-3456.github.io/blog/2025/%E4%BD%BF%E7%94%A8lme4%E5%BB%BA%E7%AB%8B%E7%BA%BF%E6%80%A7%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/" rel="alternate" type="text/html" title="使用lme4建立线性混合模型"/><published>2025-01-10T00:00:00+00:00</published><updated>2025-01-10T00:00:00+00:00</updated><id>https://pinapple-3456.github.io/blog/2025/%E4%BD%BF%E7%94%A8lme4%E5%BB%BA%E7%AB%8B%E7%BA%BF%E6%80%A7%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B</id><content type="html" xml:base="https://pinapple-3456.github.io/blog/2025/%E4%BD%BF%E7%94%A8lme4%E5%BB%BA%E7%AB%8B%E7%BA%BF%E6%80%A7%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/"><![CDATA[<h1 id="线性混合模型">线性混合模型</h1> <p>社会科学研究中的数据经常具有层次结构，过去分析层次结构数据容易产生的一个问题是汇总偏差，即将不同组织的数据错误地纳入同一个模型中。例如对不同学校的学生的调查显示，学生的某种特质X可能会影响到学习成绩Y，然而X对Y的回归系数却不是恒定的，而是在不同学校间存在有统计意义的差异。线性混合模型的出现就是为了应对这种问题。应对的策略是允许X对Y的回归系数在一定范围内变化。</p> <p>考虑以上的以上的例子，使用普通的ols回归可以建立回归方程：</p> \[\begin{align} Y_i = \beta_0 + \beta_1X_i + e_i \end{align}\] <p>其中 \(i\) 代表第 \(i\) 个学生个体。</p> <p>混合模型可以允许回归系数在不同学校间有差异，注意(3)和(4)的因变量是(2)的回归系数：</p> \[\begin{align} &amp; Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + u_{0j} \\ &amp; \beta_{1j} = \gamma_{10} + u_{1j} \end{align}\] <p>其中 \(j\) 表示第 \(j\) 个学校， \(r_{ij}\) 表示学生水平的误差， \(u_{0j}\) 和 \(u_{1j}\) 表示学校水平在截距和斜率上的误差，即不同学校间截距和斜率的差异。我们将第一行的方程称为层1，代表学生水平，将后两行的方程称为层2，代表学校水平。</p> <p>如果 \(\beta_0\) 和 \(\beta_1\) 还能够被学校特征W预测，那么有</p> \[\begin{align} &amp; Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + \gamma_{01}W_{j} + u_{0j} \\ &amp; \beta_{1j} = \gamma_{10} + \gamma_{11}W_{j} + u_{1j} \end{align}\] <p>我们可以将混合模型进行合并：</p> \[\begin{align} Y_{ij} = \gamma_{00} + \gamma_{10}X_{ij} + \gamma_{01}W_{j} + \gamma_{11}X_{ij}W_{j} + u_{0j} + u_{1j}X_{ij} + r_{ij} \end{align}\] <p>对应的普通ols回归方程是一个包含X和W交互项的方程：</p> \[\begin{align} Y_i = \beta_0 + \beta_1X_i + \beta_2W_j + \beta_3X_iW_j+ e_i \end{align}\] <p>对比普通ols回归方程，可以发现二者的区别在于原本的误差项 \(e_i\) 变为 \(u_{0j}+u_{1j}X_{ij}+r_{ij}\) 。实际上这正是线性混合模型与一般线性模型的主要区别：线性混合模型允许更加复杂的残差结构，这些残差依赖于 \(u_{0j}\) 和 \(u_{1j}\) ，因此在各学校中是不同的。线性混合模型中，残差被称为随机效应，其中 \(r_{ij}\) 称为层1残差， \(u_{0j}\) 称为截距的随机效应， \(u_{1j}\) 称为X斜率的随机效应。相应地，固定效应则是合并模型(8)中的系数，其中 \(\gamma_{00}\) 是截距的固定效应， \(\gamma_{10}\) 是X的固定效应， \(\gamma_{01}\) 是W的固定效应， \(\gamma_{11}\) 是X和W交互项的固定效应。熟悉随机效应和固定效应的含义有助于理解nlme的公式设定和结果。</p> <p>对于固定效应，我们关注的是它的系数，而对于随机效应，我们关注随机效应的方差和协方差。层1随机效应的方差记为 \(\mathrm{Var}(r_{ij}) = \sigma^2\) ，层2随机效应协方差阵为：</p> \[\begin{align} \left.\mathrm{Var}\left[ \begin{array} {c}u_{0j} \\ \\ u_{1j} \end{array}\right.\right]= \begin{bmatrix} \tau_{00} &amp; \tau_{01} \\ \\ \tau_{10} &amp; \tau_{11} \end{bmatrix} \end{align}\] <h1 id="实例">实例</h1> <p>这里主要展示计算过程，语句设置的要点参照下节。</p> <p>数据来自刘红云<a href="http://crup.com.cn/Book/TextDetail?doi=371b74c6-6b77-4f96-9c81-a0acd521f5e9">高级心理统计</a>第十三章13-3.SAV。其中，我们需要用到的变量有：</p> <ol> <li>因变量：mathach学生的数学成绩</li> <li>自变量：ses社会经济地位</li> <li>学校编码：id</li> <li>学校特征：disclim学校纪律环境</li> </ol> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>library(haven) #读sav文件
library(nlme) #拟合线性混合模型

df &lt;- read_sav('/Users/tan/Downloads/高级心理统计/13第十三章 多层线性模型简介/13-3.SAV') #文件导入
</code></pre></div></div> <h2 id="零模型-单因素方差分析">零模型 (单因素方差分析)</h2> <p>线性混合模型的建模的一般程序是从简单到复杂，逐步加入变量。最简单的模型被称为零模型，可以为我们提供一些初步的信息，它在层1和层2都只包含截距：</p> \[\begin{align} &amp; Y_{ij}(mathach) = \beta_{0j} + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + u_{0j} \\ \end{align}\] <p>合并模型为：</p> \[\begin{align} Y_{ij}(mathach) = \gamma_{00} + u_{0j} + r_{ij} \end{align}\] <p>零模型实际上是一个带随机效应的单因素方差分析模型。包含一个固定效应：</p> <ul> <li>\(\gamma_{00}\) 表示总均值</li> </ul> <p>两个随机效应：</p> <ul> <li>\(u_{0j}\) 代表学校间差异，方差为 \(\tau_{00}\) 。</li> <li>\(r_{ij}\) 代表学生个体差异，方差为 \(\sigma^2\) 。</li> </ul> <p>学校间差异和学生个体差异构成了总变异 \((\tau_{00}+\sigma^2)\) 。</p> <p>零模型为我们提供了分层数据的初步信息：对总平均数的估计 \(\gamma_{00}\) ，学校间方差 \(\tau_{00}\) ，学生个体间方差 \(\sigma^2\) ，以及学校间方差对总方差的解释率（ICC系数）。</p> <p>计算程序为：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lmm_null &lt;- lmerTest::lmer(mathach ~ 1 + (1|id), data = df, REML = FALSE, 
                 control = lmerControl(optimizer = 'bobyqa'))
summary(lmm_null)
</code></pre></div></div> <p>mathach ~ 1 表明固定部分只包含一个截距 \(\gamma_{00}\) ， (1|id) 表明层2随机效应也只包含截距的随机效应 \(u_{0j}\) ，依赖于学校id。</p> <p>计算的结果为：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite's method ['lmerModLmerTest']
Formula: mathach ~ 1 + (1 | id)
   Data: df
Control: lmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
 47121.8  47142.4 -23557.9  47115.8     7182 

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-3.06262 -0.75365  0.02676  0.76070  2.74184 

Random effects:
 Groups   Name        Variance Std.Dev.
 id       (Intercept)  8.553   2.925   
 Residual             39.148   6.257   
Number of obs: 7185, groups:  id, 160

Fixed effects:
            Estimate Std. Error       df t value Pr(&gt;|t|)    
(Intercept)  12.6371     0.2436 157.6209   51.87   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</code></pre></div></div> <p>Random effects 部分，给出了两个随机效应的标准差：</p> <ul> <li> <p>截距随机效应 \(u_{0j}\) 的方差 \(\tau_{00}\) 为 8.553</p> </li> <li> <p>残差 \(r_{ij}\) 的方差 \(\sigma^2\) 为 39.148</p> </li> </ul> <p>Fixed effects 部分，给出了一个固定效应：</p> <ul> <li>截距固定效应 \(\gamma_{00}\) 为12.6371。</li> </ul> <p><strong>ICC系数</strong> 零模型的一个重要作用是计算ICC系数。ICC系数是指组间方差对总方差的解释率：</p> \[\begin{align} ICC = \tau_{00}/(\tau_{00}+\sigma^2) \end{align}\] <p>ICC系数足够大，表明将模型分为学校和学生两个层次是合理的，ICC不应该低于0.059。虽然带有预测变量的模型也可以以同样的方式计算ICC，但一般的做法是使用零模型来计算。可以使用reghelper包的ICC( )函数来计算：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>library(reghelper)
ICC(lmm_null)
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1] 0.1793109
</code></pre></div></div> <p>表明零模型的ICC系数为0.1793109，组间差异足够大，建立混合模型是合理的。</p> <h2 id="随机斜率模型-随机系数模型">随机斜率模型 (随机系数模型)</h2> <p>在零模型的基础上，设置个体水平的回归方程，使层1包含预测变量ses，并且允许层1系数带有随机效应，就构成了随机斜率模型：</p> \[\begin{align} &amp; Y_{ij}(mathach) = \beta_{0j} + \beta_{1j}X_{ij}(ses) + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + u_{0j} \\ &amp; \beta_{1j} = \gamma_{10} + u_{1j} \end{align}\] <p>合并模型为：</p> \[\begin{align} Y_{ij}(mathach) = \gamma_{00} + \gamma_{10}X_{ij}(ses) + u_{0j} + u_{1j}X_{ij}(ses) + r_{ij} \\ \end{align}\] <p>包含两个固定效应：</p> <ul> <li>\(\gamma_{00}\) 表示控制ses后各学校的调整均值的总均值</li> <li>\(\gamma_{10}\) 表示各学校ses斜率的均值</li> </ul> <p>三个随机效应：</p> <ul> <li>\(u_{0j}\) 表示调整均值的学校间差异，方差为 \(\tau_{00}\) 。</li> <li>\(u_{1j}\) 表示各学校间ses斜率的差异，方差为 \(\tau_{11}\) 。</li> <li>\(r_{ij}\) 表示ses无法解释的学生个体差异，方差为 \(\sigma^2\) 。</li> </ul> <p>在随机斜率模型中，我们建构了学生水平的回归方程。随机斜率模型能够提供：每个学校回归方程的平均截距 \(\gamma_{00}\) 和斜率 \(\gamma_{10}\) ，斜率和截距在学校间的变化程度 \(u_{0j}\) 和 \(u_{1j}\) ，以及二者的相关系数 \(\rho(u_{0j}, u_{1j})\) 。这个相关系数的含义是：当学校平均成绩变化时，ses斜率随着平均成绩变化的程度。</p> <p>计算程序为：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lmm_random_coef &lt;- lmerTest::lmer(mathach ~ 1 + ses + (1 + ses|id), data = df, REML = FALSE, 
                 control = lmerControl(optimizer = 'bobyqa'))
summary(lmm_random_coef)
</code></pre></div></div> <p>与零模型相比，固定部分中加入了预测变量ses，同时在随机部分中也加入了ses斜率的随机效应。结果为：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite's method ['lmerModLmerTest']
Formula: mathach ~ 1 + ses + (1 + ses | id)
   Data: df
Control: lmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
 46648.5  46689.7 -23318.2  46636.5     7179 

Scaled residuals: 
     Min       1Q   Median       3Q      Max 
-3.12298 -0.73009  0.02184  0.75598  2.94309 

Random effects:
 Groups   Name        Variance Std.Dev. Corr 
 id       (Intercept)  4.7852  2.1875        
          ses          0.3983  0.6311   -0.11
 Residual             36.8316  6.0689        
Number of obs: 7185, groups:  id, 160

Fixed effects:
            Estimate Std. Error       df t value Pr(&gt;|t|)    
(Intercept)  12.6656     0.1891 146.4092   66.98   &lt;2e-16 ***
ses           2.3949     0.1177 158.4822   20.35   &lt;2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Correlation of Fixed Effects:
    (Intr)
ses -0.046
</code></pre></div></div> <p>Random effects 部分，给出了三个随机效应的标准差：</p> <ul> <li> <p>截距随机效应 \(u_{0j}\) 的方差 \(\tau_{00}\) 为 4.7852</p> </li> <li> <p>ses斜率随机效应 \(u_{1j}\) 的方差 \(\tau_{11}\) 为 0.3983</p> </li> <li> <p>残差 \(r_{ij}\) 的方差 \(\sigma^2\) 为 36.8316</p> </li> <li> <p>随机效应相关系数相关系数 \(\rho(u_{0j}, u_{1j})\) 为 -0.11。</p> </li> </ul> <p>Fixed effects 部分，给出了两个固定效应：</p> <ul> <li> <p>截距固定效应 \(\gamma_{00}\) 为 12.6656</p> </li> <li> <p>ses斜率固定效应 \(\gamma_{10}\) 为 2.3949</p> </li> </ul> <p><strong>随机效应方差</strong> 可以通过VarCorr函数输出随机效应的方差和协方差：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>as.data.frame(VarCorr(lmm_random_coef))
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       grp        var1 var2       vcov      sdcor
1       id (Intercept) &lt;NA&gt;  4.7851695  2.1875030
2       id         ses &lt;NA&gt;  0.3983228  0.6311282
3       id (Intercept)  ses -0.1558678 -0.1128990
4 Residual        &lt;NA&gt; &lt;NA&gt; 36.8315554  6.0689007
</code></pre></div></div> <p>其中 vcov 列为方差和协方差。结果表明，残差方差 \(\sigma^2\) 为 36.8315554，随机效应协方差阵为：</p> \[\begin{align} \left.\mathrm{Var}\left[ \begin{array} {c}u_{0j} \\ \\ u_{1j} \end{array}\right.\right]= \begin{bmatrix} \tau_{00} &amp; \tau_{01} \\ \\ \tau_{10} &amp; \tau_{11} \end{bmatrix}= \begin{bmatrix} 4.7851695 &amp; -0.1558678 \\ \\ -0.1558678 &amp; 0.3983228 \end{bmatrix} \end{align}\] <p>这些方差成分可以用来计算随机效应的相关系数和各层变量的方差解释率。</p> <p><strong>随机效应的相关系数</strong> 当模型中有多个层2随机效应时，可以通过随机效应的协方差阵计算各随机效应之间的相关。例如上面的模型中包含两个层2随机效应 \(u_{0j}\) 和 \(u_{1j}\) ，他们的相关系数为：</p> \[\begin{align} ρ(u_{0j}​,u_{1j​}) = \tau_{01}/\sqrt{\tau_{00}\tau_{11}} \end{align}\] <p>summary( ) 中直接给出了相关系数为 -0.11，使用上面的方差成分也可以算出一样的结果。考察随机效应的相关是非常重要的，如果两个随机效应具有非常高的相关，表明两个系数的学校间差异可能有共同的原因，这时可以根据理论假设将其中一个系数设置为固定来简化模型。</p> <p><strong>新纳入层1变量的方差解释率</strong> 层1加入预测变量ses后，残差方差 \(\sigma^2\) 由39.148变为36.8316，可以计算层1预测变量的方差解释率：</p> \[\begin{align} R^2_{ses} = (\sigma^2_{null}-\sigma^2_{ses})/\sigma^2_{null} \end{align}\] <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sigma2_ses &lt;-  #提取随机斜率模型的残差方差
  as.data.frame(VarCorr(lmm_random_coef))[as.data.frame(VarCorr(lmm_random_coef))$grp == 'Residual', 'vcov'] 
sigma2_null &lt;-  #提取零模型的残差方差
  as.data.frame(VarCorr(lmm_null))[as.data.frame(VarCorr(lmm_null))$grp == 'Residual', 'vcov'] 
R2 = (sigma2_null - sigma2_ses)/sigma2_null  #计算R^2
R2
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1] 0.05918107
</code></pre></div></div> <p>表明加入ses后，模型解释的方差增加了5.92%。</p> <p><strong>模型的对数似然</strong> 另一种判断新纳入变量是否有效的方法是比较模型的对数似然LL。-2LL渐进服从卡方分布，可以进行似然比卡方检验，从而得到p值来辅助判断。但需要注意：(1) 必须使用完全极大似然估计，(2) 新模型必须包含旧模型的所有变量。可以使用 anova() 函数来进行检验：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>anova(lmm_random_coef,lmm_null) 
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Data: df
Models:
lmm_null: mathach ~ 1 + (1 | id)
lmm_random_coef: mathach ~ 1 + ses + (1 + ses | id)
                npar   AIC   BIC logLik deviance  Chisq Df Pr(&gt;Chisq)    
lmm_null           3 47122 47142 -23558    47116                         
lmm_random_coef    6 46648 46690 -23318    46636 479.34  3  &lt; 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</code></pre></div></div> <p>表明卡方变化值为479.34，自由度变化值为3，随机斜率模型的拟合优度显著高于零模型。</p> <h2 id="全模型-以为结果的模型">全模型 (以为结果的模型)</h2> <p>在随机斜率模型中，我们设置了层1的回归方程并允许层1系数带有变异。全模型的目的是进一步解释这些变异的来源，也就是在层2加入预测变量（学校特征），使他们预测层1系数：</p> \[\begin{align} &amp; Y_{ij}(mathach) = \beta_{0j} + \beta_{1j}X_{ij}(ses) + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + \gamma_{01}W_{j}(disclim) + u_{0j} \\ &amp; \beta_{1j} = \gamma_{10} + \gamma_{11}W_{j}(disclim) + u_{1j} \end{align}\] <p>合并模型为：</p> \[\begin{align} Y_{ij}(mathach) = \gamma_{00} + \gamma_{10}X_{ij}(ses) + \gamma_{01}W_{j}(disclim) + \gamma_{11}X_{ij}(ses)W_{j}(disclim) + u_{0j} + u_{1j}X_{ij}(ses) + r_{ij} \end{align}\] <p>包含四个固定效应：</p> <ul> <li>\(\gamma_{00}\) 是控制其他所有变量后的总截距</li> <li>\(\gamma_{01}\) 是学校纪律环境的主效应</li> <li>\(\gamma_{10}\) 是学生ses的主效应</li> <li>\(\gamma_{11}\) 是学生ses和学校纪律环境的跨层交互作用</li> </ul> <p>三个随机效应：</p> <ul> <li>\(u_{0j}\) 表示纪律环境无法解释的学校间均值差异，方差为 \(\tau_{00}\) 。</li> <li>\(u_{1j}\) 表示纪律环境无法解释的各学校间ses斜率差异，方差为 \(\tau_{11}\) 。</li> <li>\(r_{ij}\) 表示ses无法解释的学生个体差异，方差为 \(\sigma^2\) 。</li> </ul> <p>在随机斜率模型的基础上，全模型能够进一步提供：学校数学成绩均值与学校纪律环境的关系 \(\gamma_{10}\) ，ses斜率与学校纪律环境的关系 \(\gamma_{11}\) ，即跨层的交互作用。</p> <p>计算程序为：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lmm_full &lt;- lmerTest::lmer(mathach ~ 1 + ses + disclim + ses:disclim + (1 + ses|id), data = df, 
                           REML = FALSE, control = lmerControl(optimizer = 'bobyqa'))
summary(lmm_full)
</code></pre></div></div> <p>与随机斜率模型相比，随机部分不变，固定部分加入学校纪律环境主效应 disclim 和交互项 ses:disclim。结果为：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Linear mixed model fit by maximum likelihood . t-tests use Satterthwaite's method ['lmerModLmerTest']
Formula: mathach ~ 1 + ses + disclim + ses:disclim + (1 + ses | id)
   Data: df
Control: lmerControl(optimizer = "bobyqa")

     AIC      BIC   logLik deviance df.resid 
 46590.3  46645.3 -23287.2  46574.3     7177 

Scaled residuals: 
    Min      1Q  Median      3Q     Max 
-3.0406 -0.7342  0.0225  0.7579  3.2767 

Random effects:
 Groups   Name        Variance Std.Dev. Corr
 id       (Intercept)  3.6695  1.9156       
          ses          0.1566  0.3957   0.44
 Residual             36.7963  6.0660       
Number of obs: 7185, groups:  id, 160

Fixed effects:
            Estimate Std. Error       df t value Pr(&gt;|t|)    
(Intercept)  12.6606     0.1698 147.7548  74.569  &lt; 2e-16 ***
ses           2.4112     0.1100 157.4166  21.928  &lt; 2e-16 ***
disclim      -1.1275     0.1757 151.2843  -6.418 1.68e-09 ***
ses:disclim   0.5711     0.1174 180.9257   4.865 2.48e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Correlation of Fixed Effects:
            (Intr) ses   disclm
ses         0.128              
disclim     0.043  0.088       
ses:disclim 0.091  0.050 0.114 
</code></pre></div></div> <p>Random effects 部分，给出了三个随机效应的标准差：</p> <ul> <li> <p>截距随机效应 \(u_{0j}\) 的方差 \(\tau_{00}\) 为 3.6695</p> </li> <li> <p>ses斜率随机效应 \(u_{1j}\) 的方差 \(\tau_{11}\) 为 0.1566</p> </li> <li> <p>残差随机效应 \(r_{ij}\) 的方差 \(\sigma^2\) 为 36.7963</p> </li> <li> <p>随机效应相关系数相关系数 \(\rho(u_{0j}, u_{1j})\) 为 0.44。</p> </li> </ul> <p>Fixed effects 部分，给出了四个固定效应：</p> <ul> <li> <p>截距效应 \(\gamma_{00}\) 为 12.6606</p> </li> <li> <p>学校纪律环境主效应 \(\gamma_{01}\) 为 -1.1275</p> </li> <li> <p>学生ses主效应 \(\gamma_{10}\) 为 2.4112</p> </li> <li> <p>学生ses和学校纪律环境的跨层交互作用 \(\gamma_{11}\) 为 0.5711</p> </li> </ul> <p><strong>随机效应方差</strong> 同样通过VarCorr( ) 函数输出随机效应的方差和协方差：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>as.data.frame(VarCorr(lmm_full))
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       grp        var1 var2       vcov     sdcor
1       id (Intercept) &lt;NA&gt;  3.6695224 1.9155998
2       id         ses &lt;NA&gt;  0.1566169 0.3957485
3       id (Intercept)  ses  0.3327761 0.4389632
4 Residual        &lt;NA&gt; &lt;NA&gt; 36.7962906 6.0659946
</code></pre></div></div> <p>残差方差 \(\sigma^2\) 为 36.7962906，随机效应协方差阵为：</p> \[\begin{align} \left.\mathrm{Var}\left[ \begin{array} {c}u_{0j} \\ \\ u_{1j} \end{array}\right.\right]= \begin{bmatrix} \tau_{00} &amp; \tau_{01} \\ \\ \tau_{10} &amp; \tau_{11} \end{bmatrix}= \begin{bmatrix} 3.6695224 &amp; 0.3327761 \\ \\ 0.3327761 &amp; 0.1566169 \end{bmatrix} \end{align}\] <p><strong>层2变量的方差解释率</strong> 层2加入截距和斜率预测变量，解释了一部分学校间截距和斜率差异，可以计算这一方差解释率。与层1相似，层2截距模型方差解释率为 \((\tau_{00(ses)} - \tau_{00(full)}) / \tau_{00(ses)}\) ，层2斜率模型的方差解释率为 \((\tau_{11(ses)} - \tau_{11(full)}) / \tau_{11(ses)}\) 。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 学校纪律环境对学校截距差异的方差解释率
tau00_full &lt;-  #全模型层2截距模型残差方差
  as.data.frame(VarCorr(lmm_full))[as.data.frame(VarCorr(lmm_full))$var1 == '(Intercept)', 'vcov'][1]
tau00_ses &lt;-  #随机斜率模型层2截距模型残差方差
  as.data.frame(VarCorr(lmm_random_coef))[as.data.frame(VarCorr(lmm_random_coef))$var1 == '(Intercept)', 'vcov'][1] 
R2 = (tau00_ses - tau00_full)/tau00_ses  #计算R^2
R2
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1] 0.2331468
</code></pre></div></div> <p>表明学校纪律环境解释了 23.31% 的学校间截距差异。</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>## 学校纪律环境对学校ses斜率差异的方差解释率
tau11_full &lt;-  #全模型层2斜率模型残差方差
  as.data.frame(VarCorr(lmm_full))[as.data.frame(VarCorr(lmm_full))$var1 == 'ses', 'vcov'][1]
tau11_ses &lt;-  #随机斜率模型层2斜率模型残差方差
  as.data.frame(VarCorr(lmm_random_coef))[as.data.frame(VarCorr(lmm_random_coef))$var1 == 'ses', 'vcov'][1] 
R2 = (tau11_ses - tau11_full)/tau11_ses  #计算R^2
R2
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[1] 0.6068091
</code></pre></div></div> <p>表明学校纪律环境解释了 60.68% 的学校间ses斜率差异。</p> <p><strong>模型比较</strong> 使用似然比卡方检验来比较全模型和随机斜率模型：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>anova(lmm_full, lmm_random_coef)
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Data: df
Models:
lmm_random_coef: mathach ~ 1 + ses + (1 + ses | id)
lmm_full: mathach ~ 1 + ses + disclim + ses:disclim + (1 + ses | id)
                npar   AIC   BIC logLik deviance  Chisq Df Pr(&gt;Chisq)    
lmm_random_coef    6 46648 46690 -23318    46636                         
lmm_full           8 46590 46645 -23287    46574 62.165  2   3.17e-14 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
</code></pre></div></div> <p>表明全模型的拟合优度显著高于随机斜率模型。</p> <h1 id="lmer的参数设置">lmer的参数设置</h1> <p><strong>公式</strong> lme4的公式是根据合并模型设置的，分为固定和随机两个部分。例如在上面的全模型中，固定部分为：</p> \[\gamma_{00} + \gamma_{10}X_{ij}(ses) + \gamma_{01}W_{j}(disclim) + \gamma_{11}X_{ij}(ses)W_{j}(disclim)\] <p>固定部分语法与 lm( ) 一致，设置为mathach ~ ses + disclim + ses:disclim，或 mathach ~ ses*disclim。</p> <p>随机部分为：</p> \[u_{0j} + u_{1j}X_{ij}(ses) + r_{ij}\] <p>随机部分左右两侧用竖线隔开，左侧是需要设置随机效应的参数，右侧是组的编码。例如在以上的例子中， \(u_{0j}\) 和 \(u_{1j}\) 分别为截距和斜率的随机效应随着学校变化，残差 \(r_{ij}\) 不需要设置，因此随机部分设置为 (1 + ses|id) 。表明截距和ses的斜率在学校间变化。截距一般可以省略掉，变为 (ses|id) 。如果希望截距固定，则将1改成0，变为 (0 + ses|id) 。</p> <p><strong>估计方法</strong> 线性混合模型一般使用完全极大似然法(ML)和受限极大似然法(REML)进行估计。REML假定固定效应的结构是正确的，能够为随机效应提供更准确的估计，相反，ML能够为固定效应提供能准确的估计。多数软件默认使用REML估计，但具体使用哪一种取决于研究目的。在使用对数似然进行模型比较时，如果新模型在旧模型基础上加入了新的变量，则两个模型必须使用ML估计。如果新模型只在旧模型1的基础上加入了新的随机效应，那么两个模型都应该使用REML估计，这种方法适合于评估随机效应设置的合理性。可以通过 REML = TRUE 或 FALSE 来指定估计方法。</p> <p><strong>畸形拟合</strong> 有时模型拟合后会显示警告 ”boundary (singular) fit: see help(‘isSingular’)“，表明在允许的最大迭代次数后结果没有收敛，这时的结果是不可信的。此时首选的解决方法是更改优化算法。可以在 lmer 中添加参数 control = lmerControl(optimizer = “选择的优化器” 。以上的例子中全部使用了bobyqa优化算法。可以使用 afex 包的 allFit( ) 函数来帮助选择优化算法，以上面的全模型为例：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>library(afex)
lmm_full &lt;- lme4::lmer(mathach ~ ses + disclim + ses:disclim + (1 + ses|id),data = df)
allFit(lmm_full)
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bobyqa : [OK]
Nelder_Mead : [OK]
nlminbwrap : [OK]
nloptwrap.NLOPT_LN_NELDERMEAD : [OK]
nloptwrap.NLOPT_LN_BOBYQA : boundary (singular) fit: see help('isSingular')
[OK]
original model:
mathach ~ ses + disclim + ses:disclim + (1 + ses | id) 
data:  df 
optimizers (5): bobyqa, Nelder_Mead, nlminbwrap, nloptwrap.NLOPT_LN_NELDERMEAD, nloptwrap.NLO...
differences in negative log-likelihoods:
max= 0.331 ; std dev= 0.148 
</code></pre></div></div> <p>结果表明，nloptwrap 导致了收敛警告，而其他的优化器都是可用的。另一种方法是增加迭代次数直到收敛，例如 control = lmerControl(optCtr = list(maxfun = 1e9)) 。但有时畸形拟合说明模型过于复杂，可以适当删除随机效应，或者强制随机效应之间相关为0 。强制随机效应的方法是分别设置每个随机效应，例如以上的例子里，随机部分可以改为 (1|id) + (0 + ses|id) 。</p> <h1 id="层1自变量对中问题">层1自变量对中问题</h1> <p>对中是指将自变量减去其均值，使均值变为0。这是为了使截距变得有意义，自变量均值对应的回归预测值为因变量均值，而对中后截距就是因变量的均值。截距的意义在混合模型中是一个重要问题，因为截距的意义决定了层2截距随机效应和截距预测变量的意义，因此对中是一个必要的步骤。对中有两种方式：以总均值对中和以组均值对中。本例中的自变量是预先进行过标准化的，可以看做以总均值对中。</p> <h2 id="对截距估计的影响">对截距估计的影响</h2> <p>不同对中方式得到的截距含义是不同的。</p> <p><strong>以总均值对中</strong> 以总均值对中后，层1模型变为:</p> \[\begin{align} Y_{ij} = \beta_{0j} + \beta_{1j}(X_{ij}-\bar{X}_{..}) + r_{ij} \end{align}\] <p>将学校内样本均值 \(X = \bar{X}_{.j}\) 和 \(X = \bar{Y}_{.j}\) 带入能够得到:</p> \[\begin{align} \beta_{0j} = \bar{Y}_{.j} - \beta_{1j}(X_{.j}-\bar{X}_{..}) \end{align}\] <p>是控制了自变量后每个学校的调整均值。如果希望控制个体水平的一些变量来估计截距，那么最好以总均值对中，实际研究中一般是这种情况，但前提是不存在构成效应。</p> <p><strong>以组均值对中</strong> 以组均值对中后，层1模型变为：</p> \[\begin{align} Y_{ij} = \beta_{0j} + \beta_{1j}(X_{ij}-\bar{X}_{.j}) + r_{ij} \end{align}\] <p>将学校内样本均值 \(X = \bar{X}_{.j}\) 和 \(X = \bar{Y}_{.j}\) 带入能够得到:</p> \[\begin{align} \beta_{0j} = \bar{Y}_{.j} \end{align}\] <p>这样就忽略了自变量的影响，是每个学校的未调整均值。也就是说，层2截距模型不受层1自变量的影响。</p> <h2 id="对斜率估计的影响">对斜率估计的影响</h2> <p>我们希望层1斜率是个体水平斜率的估计，但有时不必然如此，对中方式会影响层1斜率的估计。</p> <p><strong>构成效应</strong> 当把自变量分为组均值 \(\bar{X}_{.j}\) 和个体差异 \((X_{ij}-\bar{X}_{.j})\) 两个部分时， \(\bar{X}_{.j}\) 的效应 \(\beta_b\) 和 \((X_{ij}-\bar{X}_{.j})\) 的效应 \(\beta_w\) 有时存在差异，导致相同的 \(X_{ij}\) 在 \(\bar{X}_{.j}\) 更高的组具有更大或更小的效应，构成效应为 \(\beta_c = \beta_b -\beta_w\) 。</p> <p>当存在构成效应时，以总均值对中得到的 \(\beta_{1j}\) 不是个体水平的斜率，而是 \(\beta_b\) 和 \(\beta_w\) 混合而成的效应，难以解释。需要在层2截距模型中加入组均值作为协变量：</p> \[\begin{align} &amp; Y_{ij} = \beta_{0j} + \beta_{1j}(X_{ij}-\bar{X}_{..}) + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + \gamma_{01}\bar{X}_{.j} + u_{0j} \\ &amp; \beta_{1j} = \gamma_{10} \end{align}\] <p>此时有:</p> \[\begin{align} &amp; \beta_{c} = \gamma_{01} \\ &amp; \beta_{w} = \gamma_{10} \\ &amp; \beta_{b} = \gamma_{10} + \gamma_{01}\\ \end{align}\] <p>而组均值对中可以直接得到个体水平的斜率估计：</p> \[\begin{align} &amp; Y_{ij} = \beta_{0j} + \beta_{1j}(X_{ij}-\bar{X}_{.j}) + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + \gamma_{01}\bar{X}_{.j} + u_{0j} \\ &amp; \beta_{1j} = \gamma_{10} \end{align}\] <p>此时有:</p> \[\begin{align} &amp; \beta_{b} = \gamma_{01} \\ &amp; \beta_{w} = \gamma_{10} \\ &amp; \beta_{c} = \gamma_{01} - \gamma_{10}\\ \end{align}\] <h1 id="模型检验">模型检验</h1> <p>混合模型的层1和层2残差都需要满足正态性和方差齐性，可以使用 sjPlot 包的 plot_model( ) 函数来进行模型检验，以全模型为例：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>diag_plot &lt;- plot_model(lmm_full, type = "diag", dot.size = 0.4)
plot_grid(diag_plot[[1]], diag_plot[[3]], diag_plot[[4]], diag_plot[[2]]$id,
          labels = c('A', 'B', 'C', 'D'))
</code></pre></div></div> <p><img src="/assets/img/2025-1-12混合模型figure1.jpg" alt="模型诊断" title="模型诊断" height="100%" width="100%"/></p> <p>图 A、B、C 分别为层1残差的QQ图、密度图和对拟合值图。QQ图和密度图表明残差大致服从正态分布，但通过残差对拟合值图，可以看出在拟合值较低时下方有断尾，而在拟合值较高时上方有断尾，表明因变量有比较强的地板和天花板效应。图D为随机效应的QQ图，可以看出两个随机效应大致服从正态分布。</p> <h1 id="参考资料">参考资料：</h1> <ol> <li> <p>S. W. Raudenbush, A. S. Bryk. <em>分层线性模型：应用与数据分析方法</em>. 社会科学文献出版社.</p> </li> <li> <p>刘红云. <em>高级心理统计</em>. 中国人民大学出版社.</p> </li> <li> <p>Field, A., Miles, J., &amp; Field, Z. <em>Discovering statistics using R</em>. SAGE Publications.</p> </li> <li> <p>谢宇. <em>回归分析</em>. 社会科学文献出版社.</p> </li> <li> <p>Brown, V. A. (2021). <em>An Introduction to Linear Mixed-Effects Modeling in R</em>. Advances in Methods and Practices in Psychological Science. </p> </li> <li> <p><a href="https://blog.csdn.net/qq_39859424/article/details/133245358">R统计绘图-线性混合效应模型详解(理论、模型构建、检验、选择、方差分解及结果可视化)_r 混合效应模型-CSDN博客</a></p> </li> </ol>]]></content><author><name></name></author><category term="毕业论文"/><category term="心理学"/><summary type="html"><![CDATA[线性混合模型的建立和检验]]></summary></entry><entry><title type="html">信度的定义以及用信度进行假设检验</title><link href="https://pinapple-3456.github.io/blog/2023/%E4%BF%A1%E5%BA%A6%E7%9A%84%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E7%94%A8%E4%BF%A1%E5%BA%A6%E8%BF%9B%E8%A1%8C%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/" rel="alternate" type="text/html" title="信度的定义以及用信度进行假设检验"/><published>2023-10-20T00:00:00+00:00</published><updated>2023-10-20T00:00:00+00:00</updated><id>https://pinapple-3456.github.io/blog/2023/%E4%BF%A1%E5%BA%A6%E7%9A%84%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E7%94%A8%E4%BF%A1%E5%BA%A6%E8%BF%9B%E8%A1%8C%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C</id><content type="html" xml:base="https://pinapple-3456.github.io/blog/2023/%E4%BF%A1%E5%BA%A6%E7%9A%84%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E7%94%A8%E4%BF%A1%E5%BA%A6%E8%BF%9B%E8%A1%8C%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"><![CDATA[<h2 id="信度的定义">信度的定义</h2> <ol> <li>信度是一个被测团体真分数的变异数与实得分数的变异数之比： \(r_{xx} = SS_T/SS_X\)</li> <li>信度是一个被试团体的真分数与实得分数相关系数的平方： \(r_{xx} = \rho^2_{xT}\)</li> <li>信度是一个测验与它任意一个平行测验实得分数的相关系数： \(r_{xx} = \rho^2_{xx'}\)</li> </ol> <p>定义1实际上就是线性模型的拟合优度，即真分数可解释的变异占总变异的比重，回归分析中称作 \(R^2\)，具体可以参考上一篇blog。首先我们证明定义1、2等价，这与上一篇blog几乎一致。</p> \[\begin{align} \rho^2_{xT} = \left [ \frac{Cov(T, X)}{\sigma(T)\sigma(X)} \right ]^2 \end{align}\] <p>单独拿出括号中的分子，也就是实得分数与真分数的协方差：</p> \[\begin{align} &amp; \sum(t_i-\bar{t})(x_i-\bar{x}) \\ &amp; = \sum[(t_i-\bar{t})(x_i-t_i+t_i-\bar{x})] \\ &amp; = \sum[(t_i-\bar{t})(x_i-t_i)+(t_i-\bar{t})(t_i-\bar{x})] \\ &amp; = \sum[(t_i-\bar{t})e_i+(t_i-\bar{t})(t_i-\bar{x})] \\ \end{align}\] <p>根据根据经典测量理论CTT的基本假设2， \(Cov(T, E)=0\)。而且理想情况下随机误差 \(E\) 的均值是0，因此， \(\sum(t_i-\bar{t})e_i=0\)。其次，根据CTT的基本假设1，真分数是实得分数的期望值，因此同一被测团体中二者的均值相等，即 \(\bar{t} = \bar{x}\)。所以可以继续推导：</p> \[\begin{align} &amp; \sum[(t_i-\bar{t})e_i+(t_i-\bar{t})(t_i-\bar{x})] \\ &amp; = \sum[(t_i-\bar{t})(t_i-\bar{t})]\\ &amp; = \sum(t_i-\bar{t})^2 \\ \end{align}\] <p>代回(1)：</p> \[\begin{align} \rho^2_{xx'} &amp; = \left [ \frac{Cov(T, X)}{\sigma(T)\sigma(X)} \right ]^2 \\ &amp; = \left [\frac{\sum(t_i-\bar{t})^2}{\sqrt{\sum(t_i-\bar{t})^2\sum(x_i-\bar{x})^2}} \right ]^2\\ &amp; = \frac{\sum(t_i-\bar{t})^2\sum(t_i-\bar{t})^2}{\sum(t_i-\bar{t})^2\sum(x_i-\bar{x})^2}\\ &amp; = \frac{\sum(t_i-\bar{t})^2}{\sum(x_i-\bar{x})^2}\\ &amp; = \frac{SS_T}{SS_X} \end{align}\] <p>因此，真分数与实得分数的相关系数平方等于真分数变异占总变异的比重。</p> <p>接下来是定义3。测验 \(X\) 的平行测验记为 \(X'\)，根据平行测验的定义， \(T=T'\)， \(\sigma_{E}=\sigma_{E'}\)。：</p> \[\begin{align} \rho_{xx'} &amp; = \frac{Cov(X, X')}{\sigma(X)\sigma(X')} \\ &amp; = \frac{\sum(x_i - \bar{x})(x_i' - \bar{x})}{\sqrt{SS_{T}+SS_{E}} \sqrt{SS_{T'}+SS_{E'}}} \\ &amp; = \frac{\sum(t_i + e_i - \bar{x})(t_i + e_i' - \bar{x})}{(\sqrt{SS_{T}+SS_{E}})^2} \\ &amp; = \frac{\sum(t_i^2+t_ie_i'-t_i\bar{x}+e_it_i+e_ie_i'-e_i\bar{x}-\bar{x}t_i-\bar{x}e_i'+\bar{x}^2)}{SS_X} \\ \end{align}\] <p>根据CTT假设3， \(Cov(E, E')=0\)，所以 \(\sum e_ie_i'=0\)：</p> \[\begin{align} &amp; \frac{\sum(t_i^2-2t_i\bar{x}+\bar{x}^2+t_ie_i-\bar{x}e_i+t_ie_i'-\bar{x}e_i')}{SS_X} \\ &amp; = \frac{\sum(t_i-\bar{x})^2+\sum(t_i-\bar{x})e_i+\sum(t_i-\bar{x})e_i'}{SS_X} \\ &amp; = \frac{\sum(t_i-\bar{x})^2}{SS_X} \\ &amp; = \frac{SS_T}{SS_X} \end{align}\] <p>因此，两平行测验相关系数等于真分数变异占总变异的比重。定义3是实际操作中进行信度计算的理论基础，重测信度、复本信度以及分半信度都是基于定义3产生的。</p> <hr/> <h2 id="使用信度计算置信区间">使用信度计算置信区间</h2> <p>戴海崎教材中给出的误差标准误公式是：</p> \[\begin{align} \sigma_X\sqrt{1-r_{xx}} \end{align}\] <p>很容易得到：</p> \[\begin{align} &amp;\sigma_X\sqrt{1-r_{xx}}\\ &amp; = \sigma_X\sqrt{1-\frac{SS_T}{SS_X}}\\ &amp; = \sigma_X\sqrt{\frac{SS_X-SS_T}{SS_X}}\\ \end{align}\] <p>根据CTT假设，有 \(SS_X = SS_T + SS_E\)。所以可以得到：</p> \[\begin{align} &amp;\sigma_X\sqrt{\frac{SS_X-SS_T}{SS_X}}\\ &amp; = \sigma_X\sqrt{\frac{SS_E}{SS_X}}\\ &amp; = \sigma_X\sqrt{\frac{\sigma^2_E}{\sigma^2_X}}\\ &amp; = \sigma_E \end{align}\] <p>也就是误差的标准差。</p> <hr/>]]></content><author><name></name></author><category term="心理学"/><summary type="html"><![CDATA[信度的定义以及用信度进行假设检验]]></summary></entry><entry><title type="html">线性模型中R²、r、η²、f²、f、F的关系</title><link href="https://pinapple-3456.github.io/blog/2023/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%ADR-r-%CE%B7-f-f-F%E7%9A%84%E5%85%B3%E7%B3%BB/" rel="alternate" type="text/html" title="线性模型中R²、r、η²、f²、f、F的关系"/><published>2023-09-16T16:40:16+00:00</published><updated>2023-09-16T16:40:16+00:00</updated><id>https://pinapple-3456.github.io/blog/2023/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%ADR%C2%B2%E3%80%81r%E3%80%81%CE%B7%C2%B2%E3%80%81f%C2%B2%E3%80%81f%E3%80%81F%E7%9A%84%E5%85%B3%E7%B3%BB</id><content type="html" xml:base="https://pinapple-3456.github.io/blog/2023/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%ADR-r-%CE%B7-f-f-F%E7%9A%84%E5%85%B3%E7%B3%BB/"><![CDATA[<p>决定系数 \(R^2\) 原本的含义是拟合优度。</p> <p>具体来讲，在回归分析中，我们将全部观测值 \(y_i\) 偏离均值 \(\bar{y}\) 的离差平方和记作SST(Sum of Squares Total)。其中包含了观测值 \(y_i\) 偏离回归估计值 \(\hat{y_i}\) 离差平方和SSE(Sum of Squares Error)，以及估计值 \(\hat{y_i}\) 偏离平均值 \(\bar{y}\) 的离差平方和SSR(Sum of Squares Regression)。</p> \[\begin{eqnarray} SST &amp; = &amp; \sum_{i=1}^{n} (y_i-\bar{y})^2\\ &amp; = &amp; \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})+(y_i-\hat{y})]^2\\ &amp; = &amp; \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})^2+(y_i-\hat{y})^2+2(\hat{y_i}-\bar{y})(y_i-\hat{y})]\\ \end{eqnarray}\] <p>回归模型的外生性假设要求误差项与解释变量不相关，即 \(Cov(X,\varepsilon) = 0\)，我们知道回归的基本表达是 \(\hat{y_i} = b_0 + b_1 x_i\)，所以\(Cov(\hat{Y},\varepsilon) = 0\)。所以：</p> \[\begin{eqnarray} \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})^2+(y_i-\hat{y})^2+2(\hat{y_i}-\bar{y})(y_i-\hat{y})] = \sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2+ \sum_{i=1}^{n} (y_i-\hat{y})^2 = SSR + SSE \end{eqnarray}\] <p>SSE代表回归方程无法解释的变异，SSR代表回归方程可以解释的变异。SSR/SST，即可解释变异占总变异的比例，代表了回归方程的拟合优度，即 \(R^2\)。决定系数 \(R^2\) 实际上就是样本皮尔逊相关系数 \(r\) 的平方。根据 \(r\) 的计算公式很容易得到：</p> \[\begin{eqnarray} r^2 &amp; = &amp; \left[ \frac{Cov(X, Y)}{\sigma(x)\sigma(y)}\right]^2 &amp; = &amp; \frac{\left[ \sum_{i=1}^{n}(y_i-\bar{y})(x_i-\bar{x}) \right]^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2\sum_{i=1}^{n}(x_i-\bar{x})^2} \end{eqnarray}\] <p>单独拿出分子:</p> \[\begin{eqnarray} &amp;&amp; [\sum_{i=1}^{n}(y_i-\bar{y})(x_i-\bar{x})]^2\\ &amp; = &amp; [\sum_{i=1}^{n}[(y_i-\hat{y_i})+(\hat{y_i}-\bar{y})](x_i-\bar{x})]^2\\ &amp; = &amp; [\sum_{i=1}^{n}(y_i-\hat{y_i})(x_i-\bar{x})+ \sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x})]^2 \end{eqnarray}\] <p>单独拿出括号中的左半部分 \(\sum_{i=1}^{n}(y_i-\hat{y_i})(x_i-\bar{x})\)，我们知道回归的基本表达是 \(\hat{y_i} = b_0 + b_1 x_i\)，代入得到：</p> \[\begin{eqnarray} &amp;&amp; \sum_{i=1}^{n}(y_i-\hat{y})(x_i-\bar{x})\\ &amp; = &amp; \frac{1}{b_1}\sum_{i=1}^{n}(y_i-\hat{y_i})[(b_1 x_i+b_0)-(b_1\bar{x}+b_0)]\\ &amp; = &amp; \frac{1}{b_1}\sum_{i=1}^{n}(y_i-\hat{y_i})(\hat{y_i}-\bar{y}) \end{eqnarray}\] <p>与 (4) 同理，根据回归分析的外生性假设，(11) 可以直接消掉，(8) 只剩下 \([\sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x})]^2\)。然后同理将 \(y = b_0 + b_1x\) 代入:</p> \[\begin{eqnarray} &amp;&amp; [\sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x})]^2\\ &amp; = &amp; \sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x}) \sum_{i=1}^{n}(\hat{y}-\bar{y})(x_i-\bar{x})\\ &amp; = &amp; \frac{1}{b} \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})]^2 b\sum_{i=1}^{n}[(x_i-\bar{x})]^2 \\ &amp; = &amp; \sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2 \sum_{i=1}^{n} (x_i-\bar{x})^2 \end{eqnarray}\] <p>那么(5)变为：</p> \[\begin{eqnarray} &amp;&amp; \frac{\sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2 \sum_{i=1}^{n} (x_i-\bar{x})^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2\sum_{i=1}^{n}(x_i-\bar{x})^2} &amp; = &amp; \frac{\sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2} &amp; = &amp; \frac{SSR}{SST} &amp; = &amp; R^2 \end{eqnarray}\] <p>而且 \(r^2\) 同时也是方差分析中常用的效应量 \(\eta^2\)。方差分析是观测变量为分类变量的线性模型，上面证明中的SSE对应方差分析中的组间离差平方和，SSR对应组内离差平方和。</p> <p>有了 \(r^2\) 后，我们就可以计算 \(f^2\)，常见的公式是：</p> \[\begin{eqnarray} f^2 = \frac{r^2}{1-r^2} \end{eqnarray}\] <p>加上根号就可以得到 \(f\) 的公式。 习惯上把 \(f=0.1, 0.25, 0.4\)分别算作小、中、大效应。那么 \(f^2\) 的小、中、大效应应该分别是0.01，0.0625和0.16，而不是很多资料中指定的0.02，0.15和0.35。用Gpower算样本量，如果按照0.15的中等效应量，算出来的样本量会非常少，用0.06算会看起来合理一些。不过这个争论这个问题意义不大，一方面效应量的划分本来就是非常武断的，另一方面几乎没有人会用 \(f\) 或 \(f^2\) 报告效应量。比较合理的方式是根据过去类似研究确定样本量，然后计算如此样本量最小能检测到多大的效应。</p> <p>我们进一步推导。因为</p> \[\begin{eqnarray} r^2 = \frac{SSR}{SST} = \frac{SST-SSE}{SST} = 1-\frac{SSE}{SST} \end{eqnarray}\] <p>所以\(f^2\) 的含义实际上是：</p> \[\begin{eqnarray} f^2 = \frac{\frac{SSR}{SST}}{1-(1-\frac{SSE}{SST})} = \frac{SSR}{SSE} \end{eqnarray}\] <p>所以 \(f^2\) 也是一种拟合优度的指标，含义是回归模型可解释变异与不可解释变异的比值。</p> <p>但 \(f^2\) 和 \(R^2\) 不能直接进行检验，此时就需要引出 \(F\)。 \(F\) 是一个类似于 \(f^2\) 的效应值，区别在于 \(F\) 考虑了自由度，因此可以根据 \(F\) 分布进行假设检验:</p> \[\begin{eqnarray} F = \frac{SSR/1}{SSE/(n-2)} \end{eqnarray}\] <p>可以看出 \(F\) 就是在 \(f^2\) 的基础上，分子分母同时除以自由度。上面的式子是一元回归的情况，多元回归时，分子自由度为 \(k\) ，分母自由度为 \(n-k-1\) ， \(k\) 是预测变量的个数。</p>]]></content><author><name></name></author><category term="心理学"/><summary type="html"><![CDATA[这些效应值实际上都是不同版本的回归模型拟合优度。]]></summary></entry></feed>