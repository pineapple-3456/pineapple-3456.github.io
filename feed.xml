<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://pinapple-3456.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://pinapple-3456.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-29T13:08:56+00:00</updated><id>https://pinapple-3456.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">毕业论文笔记1｜使用nlme建立线性混合模型</title><link href="https://pinapple-3456.github.io/blog/2024/%E4%BD%BF%E7%94%A8nlme%E5%BB%BA%E7%AB%8B%E7%BA%BF%E6%80%A7%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/" rel="alternate" type="text/html" title="毕业论文笔记1｜使用nlme建立线性混合模型"/><published>2024-12-29T00:00:00+00:00</published><updated>2024-12-29T00:00:00+00:00</updated><id>https://pinapple-3456.github.io/blog/2024/%E4%BD%BF%E7%94%A8nlme%E5%BB%BA%E7%AB%8B%E7%BA%BF%E6%80%A7%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B</id><content type="html" xml:base="https://pinapple-3456.github.io/blog/2024/%E4%BD%BF%E7%94%A8nlme%E5%BB%BA%E7%AB%8B%E7%BA%BF%E6%80%A7%E6%B7%B7%E5%90%88%E6%A8%A1%E5%9E%8B/"><![CDATA[<h2 id="线性混合模型介绍">线性混合模型介绍</h2> <p>社会科学研究中的数据经常具有层次结构，过去分析层次结构数据容易产生的一个问题是汇总偏差，即将不同组织的数据错误地纳入同一个模型中。例如对不同学校的学生的调查显示，学生的某种特质X可能会影响到学习成绩Y，然而X对Y的回归系数却不是恒定的，而是在不同学校间存在有统计意义的差异。线性混合模型的出现就是为了应对这种问题。应对的策略是允许X对Y的回归系数在一定范围内变化。</p> <p>考虑以上的以上的例子，使用普通的ols回归可以建立回归方程：</p> \[Y_i = \beta_0 + \beta_1X_i + e_i\] <p>其中 \(i\) 代表第 \(i\) 个学生个体。</p> <p>混合模型可以允许回归系数在不同学校间有差异，注意(3)和(4)的因变量是(2)的回归系数：</p> \[\begin{align} &amp; Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + u_{0j} \\ &amp; \beta_{1j} = \gamma_{10} + u_{1j} \end{align}\] <p>其中 \(j\) 表示第 \(j\) 个学校， \(r_{ij}\) 表示学生水平的误差， \(u_{0j}\) 和 \(u_{1j}\) 表示学校水平在截距和斜率上的误差，即不同学校间截距和斜率的差异。我们将第一行的方程称为层1，代表学生水平，将后两行的方程称为层2，代表学校水平。如果 \(\beta_0\) 和 \(\beta_1\) 还能够被学校特征W预测，那么普通ols回归方程为：</p> \[Y_i = \beta_0 + \beta_1X_i + \beta_2W_j + \beta_3X_iW_j+ e_i\] <p>线性混合模型的方程为：</p> \[\begin{align} &amp; Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + \gamma_{01}W_{j} + u_{0j} \\ &amp; \beta_{1j} = \gamma_{10} + \gamma_{11}W_{j} + u_{1j} \end{align}\] <p>合并后的模型为：</p> \[Y_{ij} = \gamma_{00} + \gamma_{10}X_{ij} + \gamma_{01}W_{j} + \gamma_{11}X_{ij}W_{j} + u_{0j} + u_{1j}X_{ij} + r_{ij}\] <p>对比普通ols回归方程，可以发现二者的区别在于原本的误差项 \(e_i\) 变为 \(u_{0j}+u_{1j}X_{ij}+r_{ij}\)。实际上这正是线性混合模型与一般线性模型的主要区别：线性混合模型允许更加复杂的残差结构，这些残差依赖于 \(u_{0j}\) 和 \(u_{1j}\)，因此在各学校中是不同的。线性混合模型中，残差被称为随机效应，其中 \(r_{ij}\) 称为层1残差的随机效应， \(u_{0j}\) 称为截距的随机效应， \(u_{1j}\) 称为X的随机效应。相应地，固定效应则是合并模型(9)中的系数，其中 \(\gamma_{00}\) 是截距的固定效应， \(\gamma_{10}\) 是X的固定效应， \(\gamma_{01}\) 是W的固定效应， \(\gamma_{11}\) 是X和W交互项的固定效应。熟悉随机效应和固定效应的含义有助于理解nlme的公式设定和结果。</p> <p>对于固定效应，我们关注的是它的系数，而对于随机效应，我们关注随机效应的方差和协方差。层1随机效应的方差记为 \(\mathrm{Var}(r_{ij}) = \sigma^2\)，层2随机效应协方差记为：</p> \[\left.\mathrm{Var}\left[ \begin{array} {c}u_{0j} \\ \\ u_{1j} \end{array}\right.\right]= \begin{bmatrix} \tau_{00} &amp; \tau_{01} \\ \\ \tau_{10} &amp; \tau_{11} \end{bmatrix}\] <p>它们之后会被用来计算方差解释率和各随机效应之间的关系，在后面的实例中可以看到。</p> <h2 id="实例学生社会经济地位对数学成绩的影响">实例：学生社会经济地位对数学成绩的影响</h2> <p>数据来自刘红云<a href="http://crup.com.cn/Book/TextDetail?doi=371b74c6-6b77-4f96-9c81-a0acd521f5e9">高级心理统计</a>第十三章13-3.SAV。其中，我们需要用到的变量有：</p> <ol> <li>因变量：mathach学生的数学成绩</li> <li>自变量：ses社会经济地位</li> <li>学校编码：id</li> <li>学校特征：disclim学校纪律环境</li> </ol> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>library(haven) #读sav文件
library(nlme) #拟合线性混合模型

df &lt;- read_sav('/Users/tan/Downloads/高级心理统计/13第十三章 多层线性模型简介/13-3.SAV') #文件导入
</code></pre></div></div> <h3 id="零模型">零模型</h3> <p>线性混合模型的建模的一般程序是从简单到复杂，逐步加入变量。最简单的模型被称为零模型，可以为我们提供一些初步的信息，它在层1和层2都只包含截距：</p> \[\begin{align} &amp; Y_{ij}(mathach) = \beta_{0j} + r_{ij} \\ &amp; \beta_{0j} = \gamma_{00} + u_{0j} \\ \end{align}\] <p>合并模型为：</p> \[Y_{ij} = \gamma_{00} + u_{0j} + r_{ij}\] <p>计算程序如下：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>hlm_null &lt;- lme(mathach ~ 1, random = ~1|id, data = df, method = 'ML')
summary(hlm_null)
</code></pre></div></div> <p>零模型实际上是一个带随机效应的单因素方差分析模型。层2模型以学校为单位， \(\gamma_{00}\) 代表总体均值， \(u_{0j}\) 代表学校间差异。层1以学生为单位， \(r_{ij}\) 代表学生个体差异，学校间差异和学生个体差异构成了总变异。程序中lme函数中设置了四个参数。mathach ~ 1 表明固定部分只包含一个截距 \(\gamma_{00}\)，random = ~1|id 表明随机部分也只包含截距的随机效应 \(u_{0j}\)，依赖于学校id，data = df 表明数据来源，method = ‘ML’ 表明使用极大似然法进行估计。</p> <p><strong>估计方法</strong> 线性混合模型一般使用极大似然法(ML)和受限极大似然法(REML)进行估计。ML能够为固定效应提供能准确的估计，REML能够为随机效应提供更准确的估计。多数统计软件默认使用REML估计，本例在原教材中呈现的结果也是使用REML得到的，但具体使用哪一种取决于研究目的。需要注意，如果要使用对数似然进行模型比较，则必须使用ML估计，否则对数似然是没有意义的。</p> <p><strong>缺失值处理</strong> 有缺失值时无法计算，可以在参数中加入 na.action = na.exclude，表明忽略缺失值。</p> <p>计算的结果为：</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Linear mixed-effects model fit by REML
  Data: df 
       AIC      BIC   logLik
  47122.79 47143.43 -23558.4

Random effects:
 Formula: ~1 | id
        (Intercept) Residual
StdDev:    2.934966 6.256862

Fixed effects:  mathach ~ 1 
               Value Std.Error   DF  t-value p-value
(Intercept) 12.63697 0.2443936 7025 51.70747       0

Standardized Within-Group Residuals:
        Min          Q1         Med          Q3         Max 
-3.06312473 -0.75387398  0.02670132  0.76062171  2.74262579 

Number of Observations: 7185
Number of Groups: 160 
</code></pre></div></div> <p>结果首先给出了整个模型的信息准则AIC和BIC，越小代表拟合效果越好。logLik代表对数似然LL，越大代表拟合效果越好，随后我们要使用-2LL进行模型比较。在随机部分，给出了两个随机效应的标准差，截距随机效应 \(u_{0j}\) 的标准差 \(\sqrt{\tau_{00}}\) 为2.934966，层1残差随机效应 \(r_{ij}\) 的标准差 \(\sigma\) 为6.256862。固定效应部分给出截距固定效应 \(\gamma_{00}\) 为12.63697。</p> <h3 id="随机斜率模型">随机斜率模型</h3> <p><strong>自变量对中</strong> 对中即将数据减去均值，使其均值变为0。对中是为了使截距变得有意义，如果我们在模型中设置了随机截距或截距预测变量来解释截距的变化，那截距就应该是有意义的。一般情况下，我们期望截距是各学校的均值。考虑上面的随机斜率模型， \(\beta_{0j}\) 应该是总体均值，在层1模型中，截距代表自变量为0时所对应的因变量的预测值，</p> <h3 id="待续">待续</h3>]]></content><author><name></name></author><category term="心理学"/><summary type="html"><![CDATA[使用nlme建立线性混合模型]]></summary></entry><entry><title type="html">信度的三个定义以及用信度进行假设检验</title><link href="https://pinapple-3456.github.io/blog/2023/%E4%BF%A1%E5%BA%A6%E7%9A%84%E4%B8%89%E4%B8%AA%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E7%94%A8%E4%BF%A1%E5%BA%A6%E8%BF%9B%E8%A1%8C%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/" rel="alternate" type="text/html" title="信度的三个定义以及用信度进行假设检验"/><published>2023-10-20T11:12:00+00:00</published><updated>2023-10-20T11:12:00+00:00</updated><id>https://pinapple-3456.github.io/blog/2023/%E4%BF%A1%E5%BA%A6%E7%9A%84%E4%B8%89%E4%B8%AA%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E7%94%A8%E4%BF%A1%E5%BA%A6%E8%BF%9B%E8%A1%8C%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C</id><content type="html" xml:base="https://pinapple-3456.github.io/blog/2023/%E4%BF%A1%E5%BA%A6%E7%9A%84%E4%B8%89%E4%B8%AA%E5%AE%9A%E4%B9%89%E4%BB%A5%E5%8F%8A%E7%94%A8%E4%BF%A1%E5%BA%A6%E8%BF%9B%E8%A1%8C%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/"><![CDATA[<h2 id="信度的定义">信度的定义</h2> <ol> <li>信度是一个被测团体真分数的变异数与实得分数的变异数之比： \(r_{xx} = SS_T/SS_X\)</li> <li>信度是一个被试团体的真分数与实得分数相关系数的平方： \(r_{xx} = \rho^2_{xT}\)</li> <li>信度是一个测验与它任意一个平行测验实得分数的相关系数： \(r_{xx} = \rho^2_{xx'}\)</li> </ol> <p>定义1实际上就是线性模型的拟合优度，即真分数可解释的变异占总变异的比重，回归分析中称作 \(R^2\)，具体可以参考上一篇blog。首先我们证明定义1、2等价，这与上一篇blog几乎一致。</p> \[\begin{align} \rho^2_{xT} = \left [ \frac{Cov(T, X)}{\sigma(T)\sigma(X)} \right ]^2 \end{align}\] <p>单独拿出括号中的分子，也就是实得分数与真分数的协方差：</p> \[\begin{align} &amp; \sum(t_i-\bar{t})(x_i-\bar{x}) \\ &amp; = \sum[(t_i-\bar{t})(x_i-t_i+t_i-\bar{x})] \\ &amp; = \sum[(t_i-\bar{t})(x_i-t_i)+(t_i-\bar{t})(t_i-\bar{x})] \\ &amp; = \sum[(t_i-\bar{t})e_i+(t_i-\bar{t})(t_i-\bar{x})] \\ \end{align}\] <p>根据根据经典测量理论CTT的基本假设2， \(Cov(T, E)=0\)。而且理想情况下随机误差 \(E\) 的均值是0，因此， \(\sum(t_i-\bar{t})e_i=0\)。其次，根据CTT的基本假设1，真分数是实得分数的期望值，因此同一被测团体中二者的均值相等，即 \(\bar{t} = \bar{x}\)。所以可以继续推导：</p> \[\begin{align} &amp; \sum[(t_i-\bar{t})e_i+(t_i-\bar{t})(t_i-\bar{x})] \\ &amp; = \sum[(t_i-\bar{t})(t_i-\bar{t})]\\ &amp; = \sum(t_i-\bar{t})^2 \\ \end{align}\] <p>代回(1)：</p> \[\begin{align} \rho^2_{xx'} &amp; = \left [ \frac{Cov(T, X)}{\sigma(T)\sigma(X)} \right ]^2 \\ &amp; = \left [\frac{\sum(t_i-\bar{t})^2}{\sqrt{\sum(t_i-\bar{t})^2\sum(x_i-\bar{x})^2}} \right ]^2\\ &amp; = \frac{\sum(t_i-\bar{t})^2\sum(t_i-\bar{t})^2}{\sum(t_i-\bar{t})^2\sum(x_i-\bar{x})^2}\\ &amp; = \frac{\sum(t_i-\bar{t})^2}{\sum(x_i-\bar{x})^2}\\ &amp; = \frac{SS_T}{SS_X} \end{align}\] <p>因此，真分数与实得分数的相关系数平方等于真分数变异占总变异的比重。</p> <p>接下来是定义3。测验 \(X\) 的平行测验记为 \(X'\)，根据平行测验的定义， \(T=T'\)， \(\sigma_{E}=\sigma_{E'}\)。：</p> \[\begin{align} \rho_{xx'} &amp; = \frac{Cov(X, X')}{\sigma(X)\sigma(X')} \\ &amp; = \frac{\sum(x_i - \bar{x})(x_i' - \bar{x})}{\sqrt{SS_{T}+SS_{E}} \sqrt{SS_{T'}+SS_{E'}}} \\ &amp; = \frac{\sum(t_i + e_i - \bar{x})(t_i + e_i' - \bar{x})}{(\sqrt{SS_{T}+SS_{E}})^2} \\ &amp; = \frac{\sum(t_i^2+t_ie_i'-t_i\bar{x}+e_it_i+e_ie_i'-e_i\bar{x}-\bar{x}t_i-\bar{x}e_i'+\bar{x}^2)}{SS_X} \\ \end{align}\] <p>根据CTT假设3， \(Cov(E, E')=0\)，所以 \(\sum e_ie_i'=0\)：</p> \[\begin{align} &amp; \frac{\sum(t_i^2-2t_i\bar{x}+\bar{x}^2+t_ie_i-\bar{x}e_i+t_ie_i'-\bar{x}e_i')}{SS_X} \\ &amp; = \frac{\sum(t_i-\bar{x})^2+\sum(t_i-\bar{x})e_i+\sum(t_i-\bar{x})e_i'}{SS_X} \\ &amp; = \frac{\sum(t_i-\bar{x})^2}{SS_X} \\ &amp; = \frac{SS_T}{SS_X} \end{align}\] <p>因此，两平行测验相关系数等于真分数变异占总变异的比重。定义3是实际操作中进行信度计算的理论基础，重测信度、复本信度以及分半信度都是基于定义3产生的。</p> <hr/> <h2 id="使用信度计算置信区间">使用信度计算置信区间</h2> <p>戴海崎教材中给出的误差标准误公式是：</p> \[\begin{align} \sigma_X\sqrt{1-r_{xx}} \end{align}\] <p>很容易得到：</p> \[\begin{align} &amp;\sigma_X\sqrt{1-r_{xx}}\\ &amp; = \sigma_X\sqrt{1-\frac{SS_T}{SS_X}}\\ &amp; = \sigma_X\sqrt{\frac{SS_X-SS_T}{SS_X}}\\ \end{align}\] <p>根据CTT假设，有 \(SS_X = SS_T + SS_E\)。所以可以得到：</p> \[\begin{align} &amp;\sigma_X\sqrt{\frac{SS_X-SS_T}{SS_X}}\\ &amp; = \sigma_X\sqrt{\frac{SS_E}{SS_X}}\\ &amp; = \sigma_X\sqrt{\frac{\sigma^2_E}{\sigma^2_X}}\\ &amp; = \sigma_E \end{align}\] <p>也就是误差的标准差。</p> <hr/>]]></content><author><name></name></author><category term="心理学"/><summary type="html"><![CDATA[信度的三个定义以及用信度进行假设检验]]></summary></entry><entry><title type="html">线性模型中R²、r、η²、f²、f、F的关系</title><link href="https://pinapple-3456.github.io/blog/2023/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%ADR-r-%CE%B7-f-f-F%E7%9A%84%E5%85%B3%E7%B3%BB/" rel="alternate" type="text/html" title="线性模型中R²、r、η²、f²、f、F的关系"/><published>2023-09-16T16:40:16+00:00</published><updated>2023-09-16T16:40:16+00:00</updated><id>https://pinapple-3456.github.io/blog/2023/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%ADR%C2%B2%E3%80%81r%E3%80%81%CE%B7%C2%B2%E3%80%81f%C2%B2%E3%80%81f%E3%80%81F%E7%9A%84%E5%85%B3%E7%B3%BB</id><content type="html" xml:base="https://pinapple-3456.github.io/blog/2023/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%ADR-r-%CE%B7-f-f-F%E7%9A%84%E5%85%B3%E7%B3%BB/"><![CDATA[<p>决定系数 \(R^2\) 原本的含义是拟合优度。</p> <p>具体来讲，在回归分析中，我们将全部观测值 \(y_i\) 偏离均值 \(\bar{y}\) 的离差平方和记作SST(Sum of Squares Total)。其中包含了观测值 \(y_i\) 偏离回归估计值 \(\hat{y_i}\) 离差平方和SSE(Sum of Squares Error)，以及估计值 \(\hat{y_i}\) 偏离平均值 \(\bar{y}\) 的离差平方和SSR(Sum of Squares Regression)。</p> \[\begin{eqnarray} SST &amp; = &amp; \sum_{i=1}^{n} (y_i-\bar{y})^2\\ &amp; = &amp; \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})+(y_i-\hat{y})]^2\\ &amp; = &amp; \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})^2+(y_i-\hat{y})^2+2(\hat{y_i}-\bar{y})(y_i-\hat{y})]\\ \end{eqnarray}\] <p>回归模型的外生性假设要求误差项与解释变量不相关，即 \(Cov(X,\varepsilon) = 0\)，我们知道回归的基本表达是 \(\hat{y_i} = b_0 + b_1 x_i\)，所以\(Cov(\hat{Y},\varepsilon) = 0\)。所以：</p> \[\begin{eqnarray} \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})^2+(y_i-\hat{y})^2+2(\hat{y_i}-\bar{y})(y_i-\hat{y})] = \sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2+ \sum_{i=1}^{n} (y_i-\hat{y})^2 = SSR + SSE \end{eqnarray}\] <p>SSE代表回归方程无法解释的变异，SSR代表回归方程可以解释的变异。SSR/SST，即可解释变异占总变异的比例，代表了回归方程的拟合优度，即 \(R^2\)。决定系数 \(R^2\) 实际上就是样本皮尔逊相关系数 \(r\) 的平方。根据 \(r\) 的计算公式很容易得到：</p> \[\begin{eqnarray} r^2 &amp; = &amp; \left[ \frac{Cov(X, Y)}{\sigma(x)\sigma(y)}\right]^2 &amp; = &amp; \frac{\left[ \sum_{i=1}^{n}(y_i-\bar{y})(x_i-\bar{x}) \right]^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2\sum_{i=1}^{n}(x_i-\bar{x})^2} \end{eqnarray}\] <p>单独拿出分子:</p> \[\begin{eqnarray} &amp;&amp; [\sum_{i=1}^{n}(y_i-\bar{y})(x_i-\bar{x})]^2\\ &amp; = &amp; [\sum_{i=1}^{n}[(y_i-\hat{y_i})+(\hat{y_i}-\bar{y})](x_i-\bar{x})]^2\\ &amp; = &amp; [\sum_{i=1}^{n}(y_i-\hat{y_i})(x_i-\bar{x})+ \sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x})]^2 \end{eqnarray}\] <p>单独拿出括号中的左半部分 \(\sum_{i=1}^{n}(y_i-\hat{y_i})(x_i-\bar{x})\)，我们知道回归的基本表达是 \(\hat{y_i} = b_0 + b_1 x_i\)，代入得到：</p> \[\begin{eqnarray} &amp;&amp; \sum_{i=1}^{n}(y_i-\hat{y})(x_i-\bar{x})\\ &amp; = &amp; \frac{1}{b_1}\sum_{i=1}^{n}(y_i-\hat{y_i})[(b_1 x_i+b_0)-(b_1\bar{x}+b_0)]\\ &amp; = &amp; \frac{1}{b_1}\sum_{i=1}^{n}(y_i-\hat{y_i})(\hat{y_i}-\bar{y}) \end{eqnarray}\] <p>与 (4) 同理，根据回归分析的外生性假设，(11) 可以直接消掉，(8) 只剩下 \([\sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x})]^2\)。然后同理将 \(y = b_0 + b_1x\) 代入:</p> \[\begin{eqnarray} &amp;&amp; [\sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x})]^2\\ &amp; = &amp; \sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x}) \sum_{i=1}^{n}(\hat{y}-\bar{y})(x_i-\bar{x})\\ &amp; = &amp; \frac{1}{b} \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})]^2 b\sum_{i=1}^{n}[(x_i-\bar{x})]^2 \\ &amp; = &amp; \sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2 \sum_{i=1}^{n} (x_i-\bar{x})^2 \end{eqnarray}\] <p>那么(5)变为：</p> \[\begin{eqnarray} &amp;&amp; \frac{\sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2 \sum_{i=1}^{n} (x_i-\bar{x})^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2\sum_{i=1}^{n}(x_i-\bar{x})^2} &amp; = &amp; \frac{\sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2} &amp; = &amp; \frac{SSR}{SST} &amp; = &amp; R^2 \end{eqnarray}\] <p>而且 \(r^2\) 同时也是方差分析中常用的效应量 \(\eta^2\)。方差分析是观测变量为分类变量的线性模型，上面证明中的SSE对应方差分析中的组间离差平方和，SSR对应组内离差平方和。</p> <p>有了 \(r^2\) 后，我们就可以计算 \(f^2\)，常见的公式是：</p> \[\begin{eqnarray} f^2 = \frac{r^2}{1-r^2} \end{eqnarray}\] <p>加上根号就可以得到 \(f\) 的公式。 习惯上把 \(f=0.1, 0.25, 0.4\)分别算作小、中、大效应。那么 \(f^2\) 的小、中、大效应应该分别是0.01，0.0625和0.16，而不是很多资料中指定的0.02，0.15和0.35。用Gpower算样本量，如果按照0.15的中等效应量，算出来的样本量会非常少，用0.06算会看起来合理一些。不过这个争论这个问题意义不大，一方面效应量的划分本来就是非常武断的，另一方面几乎没有人会用 \(f\) 或 \(f^2\) 报告效应量。比较合理的方式是根据过去类似研究确定样本量，然后计算如此样本量最小能检测到多大的效应。</p> <p>我们进一步推导。因为</p> \[\begin{eqnarray} r^2 = \frac{SSR}{SST} = \frac{SST-SSE}{SST} = 1-\frac{SSE}{SST} \end{eqnarray}\] <p>所以\(f^2\) 的含义实际上是：</p> \[\begin{eqnarray} f^2 = \frac{\frac{SSR}{SST}}{1-(1-\frac{SSE}{SST})} = \frac{SSR}{SSE} \end{eqnarray}\] <p>所以 \(f^2\) 也是一种拟合优度的指标，含义是回归模型可解释变异与不可解释变异的比值。</p> <p>但 \(f^2\) 和 \(R^2\) 不能直接进行检验，此时就需要引出 \(F\)。 \(F\) 是一个类似于 \(f^2\) 的效应值，区别在于 \(F\) 考虑了自由度，因此可以根据 \(F\) 分布进行假设检验:</p> \[\begin{eqnarray} F = \frac{SSR/1}{SSE/(n-2)} \end{eqnarray}\] <p>可以看出 \(F\) 就是在 \(f^2\) 的基础上，分子分母同时除以自由度。上面的式子是一元回归的情况，多元回归时，分子自由度为 \(k\) ，分母自由度为 \(n-k-1\) ， \(k\) 是预测变量的个数。</p>]]></content><author><name></name></author><category term="心理学"/><summary type="html"><![CDATA[这些效应值实际上都是不同版本的回归模型拟合优度。]]></summary></entry></feed>