---
layout: post
title: 信度的三个定义以及用信度进行假设检验
date: 2023-10-20 11:12:00
description: 信度的三个定义以及用信度进行假设检验
tags: 心理学
categories:  
related_posts: false
---

## 信度的定义

先定义符号：信度 $$r$$，相关系数 $$\rho$$，实得分数 $$X$$，真分数 $$T$$，随机误差$$E$$，离差平方和这里按我自己的习惯写作 $$SS$$。

戴海崎版本心理与教育测量提供了三种信度的定义：

1. 信度是一个被测团体真分数的变异数与实得分数的变异数之比： $$r_{xx} = SS_T/SS_X$$
2. 信度是一个被试团体的真分数与实得分数相关系数的平方： $$r_{xx} = \rho^2_{xT}$$
3. 信度是一个测验与它任意一个平行测验实得分数的相关系数： $$r_{xx} = \rho^2_{xx'}$$

定义1实际上就是线性模型的拟合优度，即真分数可解释的变异占总变异的比重，回归分析中称作 $$R^2$$，具体可以参考上一篇blog。首先我们证明定义1、2等价，这与上一篇blog几乎一致。

$$
\begin{align}
\rho^2_{xx'} = \left [ \frac{Cov(T, X)}{\sigma(T)\sigma(X)} \right ]^2
\end{align}
$$

单独拿出括号中的分子，也就是实得分数与真分数的协方差：

$$
\begin{align}
& \Sigma(t_i-\bar{t})(x_i-\bar{x}) \\
& = \Sigma[(t_i-\bar{t})(x_i-t_i+t_i-\bar{x})] \\
& = \Sigma[(t_i-\bar{t})(x_i-t_i)+(t_i-\bar{t})(t_i-\bar{x})] \\
& = \Sigma[(t_i-\bar{t})e_i+(t_i-\bar{t})(t_i-\bar{x})] \\
\end{align}
$$

根据根据经典测量理论CTT的基本假设2， $$Cov(T, E)=0$$。而且理想情况下随机误差 $$E$$ 的均值是0，因此， $$\Sigma(t_i-\bar{t})e_i=0$$。其次，根据CTT的基本假设1，真分数是实得分数的期望值，因此我们可以认为理想条件下被测团体中二者的均值相等，即 $$\bar{t} = \bar{x}$$。所以可以继续推导：

$$
\begin{align}
& \Sigma[(t_i-\bar{t})e_i+(t_i-\bar{t})(t_i-\bar{x})] \\
& = \Sigma[(t_i-\bar{t})(t_i-\bar{t})]\\
& = \Sigma(t_i-\bar{t})^2 \\
\end{align}
$$

代回(1)：

$$
\begin{align}
\rho^2_{xx'} & = \left [ \frac{Cov(T, X)}{\sigma(T)\sigma(X)} \right ]^2 \\
& = \left [\frac{\Sigma(t_i-\bar{t})^2}{\sqrt{\Sigma(t_i-\bar{t})^2\Sigma(x_i-\bar{x})^2}} \right ]^2\\
& = \frac{\Sigma(t_i-\bar{t})^2\Sigma(t_i-\bar{t})^2}{\Sigma(t_i-\bar{t})^2\Sigma(x_i-\bar{x})^2}\\
& = \frac{\Sigma(t_i-\bar{t})^2}{\Sigma(x_i-\bar{x})^2}\\
& = \frac{SS_T}{SS_X}
\end{align}
$$

因此，真分数与实得分数的相关系数平方等于真分数变异占总变异的比重。

接下来是定义3。测验 $$X$$ 的平行测验记为 $$X'$$，根据平行测验的定义， $$T=T'$$， $$\sigma_E=\sigma_E'$$。：

$$
\begin{align}
\rho_{xx'} & = \frac{Cov(X, X')}{\sigma(X)\sigma(X')} \\
& =  \frac{\Sigma(t_i + e_i - \bar{x})(t_i + e_i' - \bar{x})}{SS_x} \\
& =  \frac{\Sigma(t_i^2+t_ie_i'-t_i\bar{x}+e_it_i+e_ie_i'-e_i\bar{x}-\bar{x}t_i-\bar{x}e_i'+\bar{x}^2)}{SS_x} \\
\end{align}
$$

根据CTT假设3， $$Cov(E, E')=0$$，所以 $$\Sigma e_ie_i'=0$$。然后与(6)、(7)同理：

$$
\begin{align}
& \frac{\Sigma(t_i^2-2t_i\bar{x}+\bar{x}^2+t_ie_i'+e_it_i-e_i\bar{x}-\bar{x}e_i')}{SS_x} \\
& =  \frac{\Sigma(t_i^2-2t_i\bar{x}+\bar{x}^2+t_ie_i-\bar{x}e_i+t_ie_i'-\bar{x}e_i')}{SS_x} \\
& =  \frac{\Sigma(t_i-\bar{x})^2+\Sigma(t_i-\bar{x})e_i+\Sigma(t_i-\bar{x})e_i'}{SS_x} \\
& =  \frac{\Sigma(t_i-\bar{x})^2+\Sigma(t_i-\bar{t})e_i+\Sigma(t_i-\bar{t})e_i'}{SS_x} \\
& =  \frac{SS_T}{SS_X}
\end{align}
$$

因此，两平行测验相关系数等于真分数变异占总变异的比重。定义3是实际操作中进行信度计算的理论基础，重测信度、复本信度以及分半信度都是基于定义3产生的。

***

## 使用信度计算置信区间

戴海崎教材中给出的误差标准误公式是：

$$
\begin{align}
\sigma_X\sqrt{1-r_{xx}}
\end{align}
$$

很容易得到：

$$
\begin{align}
&\sigma_X\sqrt{1-r_{xx}}\\
& = \sigma_X\sqrt{1-\frac{SS_T}{SS_X}}\\
& = \sigma_X\sqrt{\frac{SS_X-SS_T}{SS_X}}\\
\end{align}
$$

根据CTT假设，有 $$SS_X = SS_T + SS_E$$。所以可以得到：

$$
\begin{align}
&\sigma_X\sqrt{\frac{SS_X-SS_T}{SS_X}}\\
& = \sigma_X\sqrt{\frac{SS_E}{SS_X}}\\
& = \sigma_X\sqrt{\frac{\sigma^2_E}{\sigma^2_X}}\\
& = \sigma_E
\end{align}
$$

也就是误差分布的标准差。有了误差分布后，就可以进行假设检验。

当两个分数进行比较时，教材中的公式是：

$$
\begin{align}
\sigma_{Ed} = \sigma \sqrt{2-r_{xx}-r_{yy}}
\end{align}
$$

这里需要将 $$X$$ 和 $$Y$$ 标准化，或假设两组测验方差相等，即 $$\sigma$$。可以得到：

$$
\begin{align}
\sigma_{Ed} &= \sigma \sqrt{2-r_{xx}-r_{yy}}\\
& = \sigma \sqrt{(1-r_{xx})+(1-r_{yy})}\\
& = \sigma \sqrt{\frac{\sigma^2_{E_x}}{\sigma^2}+\frac{\sigma^2_{E_y}}{\sigma^2}}\\
& = \sqrt{\sigma^2_{E_x}+\sigma^2_{E_y}}
\end{align}
$$

这里相当于两个测验误差的合成标准误。

***



